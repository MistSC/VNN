{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict\n",
    "from six.moves import cPickle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import nnet as nn\n",
    "import criteria as er\n",
    "import util\n",
    "import VAE\n",
    "import SVAE\n",
    "import update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_acc(pred, true):\n",
    "    ll = pred - true\n",
    "    ll = np.array(ll)\n",
    "    acc = 1 - (np.nonzero(ll)[0].shape[0])/float(ll.shape[0])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of minibatch at one epoch: train  183, validation 16, test 33\n",
      "55000\n",
      "55000\n",
      "784\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "'''Load Data'''\n",
    "train_file = 'train_1ok.npy'\n",
    "valid_file = 'valid_1ok.npy'\n",
    "test_file = 'test_1ok.npy'\n",
    "    \n",
    "train=np.load(train_file)\n",
    "valid=np.load(valid_file)\n",
    "test=np.load(test_file)\n",
    "\n",
    "#train_list=np.load('train.npy')[1]\n",
    "\n",
    "\n",
    "train_feat, train_label = util.shared_dataset(train)\n",
    "valid_feat, valid_label = util.shared_dataset(valid)\n",
    "test_feat, test_label = util.shared_dataset(test) \n",
    "    \n",
    "  \n",
    "'''Coefficient Initial'''        \n",
    "batch_size = 300\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "    \n",
    "n_train_batches = train_feat.get_value(borrow=True).shape[0] // batch_size\n",
    "n_valid_batches = valid_feat.get_value(borrow=True).shape[0] // batch_size\n",
    "n_test_batches = test_feat.get_value(borrow=True).shape[0] // batch_size\n",
    "print('number of minibatch at one epoch: train  %i, validation %i, test %i' %\n",
    "    (n_train_batches, n_valid_batches, n_test_batches))\n",
    "    \n",
    "z_dim = 5 #dimension of latent variable \n",
    "x_dim = train_feat.get_value(borrow=True).shape[1]\n",
    "y_dim = train_label.get_value(borrow=True).shape[1]\n",
    "activation = None\n",
    "    \n",
    "print(train_feat.get_value(borrow=True).shape[0])\n",
    "print(train_label.get_value(borrow=True).shape[0])\n",
    "print(train_feat.get_value(borrow=True).shape[1])\n",
    "print(train_label.get_value(borrow=True).shape[1])\n",
    "\n",
    "phi_1_struct=nn.NN_struct()\n",
    "phi_1_struct.layer_dim = [x_dim+y_dim, 500, z_dim]\n",
    "phi_1_struct.activation = [None, None]\n",
    "    \n",
    "theta_1_struct=nn.NN_struct()\n",
    "theta_1_struct.layer_dim = [x_dim, 500, z_dim]\n",
    "theta_1_struct.activation = [None, None]\n",
    "\n",
    "theta_2_struct=nn.NN_struct()\n",
    "theta_2_struct.layer_dim = [z_dim+x_dim, 500, y_dim]\n",
    "theta_2_struct.activation = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = T.lscalar()  # index to a [mini]batch\n",
    "x = T.matrix('x')  # the data is presented as rasterized images\n",
    "y = T.matrix('y')  # the labels are presented as signal vector   \n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "with open('model_step_ce_1l_500h_z5.save', 'rb') as f:\n",
    "    model = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.phi_mu.HL_1.W.get_value().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_kl = SVAE.Supervised_VAE_v3_KL_1(\n",
    "    rng=rng,\n",
    "    input_x = x,\n",
    "    label_y = y,\n",
    "    batch_size = batch_size,\n",
    "    phi_1_struct = phi_1_struct,\n",
    "    theta_1_struct = theta_1_struct,\n",
    "    theta_2_struct = theta_2_struct,\n",
    "    in_dim = x_dim,\n",
    "    out_dim = y_dim,\n",
    "    model = model\n",
    "    )\n",
    "\n",
    "#cost = (classifier_kl.cost)\n",
    "        \n",
    "#gparams = [T.grad(cost, param) for param in classifier_kl.params]\n",
    "                   \n",
    "#updates = [\n",
    "#    (param, param - learning_rate * gparam)\n",
    "#    for param, gparam in zip(classifier_kl.params, gparams)\n",
    "#]\n",
    "\n",
    "updates = update.adam(loss=classifier_kl.cost, all_params=classifier_kl.params, learning_rate=0.001)\n",
    "\n",
    "#classifier_kl.phi_mu = model.phi_mu\n",
    "#classifier_kl.phi_sigma = model.phi_sigma\n",
    "#classifier_kl.theta_2 = model.theta_2\n",
    "#classifier_kl.predict = model.predict\n",
    "#print(classifier_kl.phi_sigma.OL.W.get_value())\n",
    "#print(model.phi_sigma.OL.W.get_value())\n",
    "#print(classifier_kl.theta_2.OL.W.get_value())\n",
    "#print(model.theta_2.OL.W.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{add,no_inplace}.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_kl.phi_sigma.OL.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... prepare training model\n",
      "... prepare validate model\n",
      "... prepare test model\n"
     ]
    }
   ],
   "source": [
    "print('... prepare training model')\n",
    "train_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=[classifier_kl.cost, classifier_kl.predictor, classifier_kl.label_y, classifier_kl.predictor_test,\n",
    "            classifier_kl.EC_mu, classifier_kl.EC_log_sigma, classifier_kl.DC_mu, classifier_kl.DC_log_sigma,\n",
    "            classifier_kl.KL, classifier_kl.CE],\n",
    "            #classifier_kl.KL, classifier_kl.CE],\n",
    "    updates=updates,\n",
    "    givens={\n",
    "        x: train_feat[index * batch_size : (index + 1) * batch_size, :],\n",
    "        y: train_label[index * batch_size : (index + 1) * batch_size, :]\n",
    "    }       \n",
    ")   \n",
    "    \n",
    "print('... prepare validate model')\n",
    "validate_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=classifier_kl.cost,\n",
    "    givens={\n",
    "        x: valid_feat[index * batch_size : (index + 1) * batch_size, :],\n",
    "        y: valid_label[index * batch_size : (index + 1) * batch_size, :]\n",
    "    }        \n",
    ")      \n",
    "\n",
    "\n",
    "print('... prepare test model')\n",
    "test_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=[classifier_kl.predictor_test, classifier_kl.label_y],\n",
    "    givens={\n",
    "        x: test_feat[index * batch_size : (index + 1) * batch_size, :],\n",
    "        y: test_label[index * batch_size : (index + 1) * batch_size, :]\n",
    "    }        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.29673958, -2.01758528, -3.92973495,  4.54421282,  1.45731735],\n",
      "       [-1.05627608,  3.9221909 ,  0.3522307 , -3.44412541, -3.24315524],\n",
      "       [ 0.25198454, -3.16855502,  1.21092904,  0.09754206,  0.84984988],\n",
      "       ..., \n",
      "       [-1.35591543, -0.91167819,  2.63163209, -1.59312689,  0.48162308],\n",
      "       [-1.48813903,  0.05131886, -1.52471101, -2.42803359,  1.03774703],\n",
      "       [ 0.35093445,  2.84826612,  1.87089884, -3.07873654, -1.36241007]], dtype=float32) \n",
      " decoder log variance: array([[ 0.09893712,  1.0233779 ,  1.40784562,  1.21124303,  1.09899485],\n",
      "       [ 1.11247849,  0.68719751,  0.15468182, -0.95494241,  0.53514767],\n",
      "       [ 0.02837124,  0.70941764,  1.07102537,  0.61472273,  0.36156818],\n",
      "       ..., \n",
      "       [ 1.87487257,  0.73426872,  1.22427154, -0.3520138 ,  0.37631512],\n",
      "       [ 0.49249527,  0.81167644,  0.94607908, -0.34814471,  0.96652198],\n",
      "       [ 1.4430387 ,  0.65531957,  0.4690747 , -0.36957753,  1.03378832]], dtype=float32) \n",
      "\n",
      "kl loss: -20.390209, ce loss: 0.584265 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.580219, training loss: 20.974472\n",
      "epoch 1, minibatch 183/183, validation loss 20.887568\n",
      "test accuracy: 0.815657\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99362826, -1.88707924, -3.34221601,  5.10605097,  1.32989442],\n",
      "       [-1.58442867,  4.51384926, -0.23890795, -3.36950231, -2.63996029],\n",
      "       [-0.02582756, -3.18885231,  1.19807029,  0.33201882,  1.04262006],\n",
      "       ..., \n",
      "       [-2.1506474 , -0.39940128,  3.03053999, -1.29344094,  0.72744799],\n",
      "       [-1.50890839,  0.41301033, -1.81101787, -2.32967758,  1.15702271],\n",
      "       [ 0.42272916,  3.40291262,  1.97665274, -3.27758241, -2.16389012]], dtype=float32) \n",
      " decoder log variance: array([[-0.33712494,  0.29588351,  0.87601954,  1.34218121,  0.87854576],\n",
      "       [ 0.81274945,  0.41704649,  0.06664274, -1.79502404,  0.23634517],\n",
      "       [-0.23170084,  0.40945044,  1.2850194 ,  0.44977897, -0.00642308],\n",
      "       ..., \n",
      "       [ 1.74603248,  0.40923193,  1.21378767, -0.75813216,  0.19023919],\n",
      "       [ 0.28876287,  0.87338495,  0.72830635, -1.01849091,  1.18994033],\n",
      "       [ 1.4100312 ,  0.41530028,  0.52210432, -0.66110086,  0.90053594]], dtype=float32) \n",
      "\n",
      "kl loss: -19.325338, ce loss: 0.363618 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.853097, training loss: 19.688959\n",
      "epoch 2, minibatch 183/183, validation loss 19.561443\n",
      "test accuracy: 0.899495\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.83766651, -1.77415299, -3.01505733,  5.30099058,  1.06369495],\n",
      "       [-2.0333817 ,  4.71154451, -0.34224966, -3.30193448, -2.12356663],\n",
      "       [-0.27178025, -3.21083236,  1.45173192,  0.41256902,  1.17822504],\n",
      "       ..., \n",
      "       [-2.84315681,  0.00600549,  3.22626591, -1.16514361,  0.90036315],\n",
      "       [-1.48208416,  0.47340539, -1.95355868, -2.23722196,  1.27577567],\n",
      "       [ 0.75944024,  3.50970197,  2.07518101, -3.49679661, -2.79604387]], dtype=float32) \n",
      " decoder log variance: array([[-0.9325332 , -0.36360711,  0.02121058,  0.73383862,  0.53222084],\n",
      "       [ 0.47692519,  0.07527457, -0.13337864, -2.39761162, -0.13104482],\n",
      "       [-0.4469986 ,  0.13387294,  1.15772259,  0.12207031, -0.26880807],\n",
      "       ..., \n",
      "       [ 1.47124231, -0.07896961,  0.93531615, -1.23548424, -0.21434651],\n",
      "       [ 0.07270229,  0.83877647,  0.43972126, -1.45686662,  1.31078279],\n",
      "       [ 1.19987154,  0.13110501,  0.39017275, -1.08709192,  0.57914627]], dtype=float32) \n",
      "\n",
      "kl loss: -18.400658, ce loss: 0.241294 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.909089, training loss: 18.641953\n",
      "epoch 3, minibatch 183/183, validation loss 18.628172\n",
      "test accuracy: 0.924848\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.80389094, -1.76282167, -2.94073319,  5.20764065,  1.02664399],\n",
      "       [-2.51578975,  4.61400843, -0.22922729, -3.4295404 , -1.54282963],\n",
      "       [-0.5323059 , -3.4020226 ,  1.89910948,  0.38118932,  1.52036679],\n",
      "       ..., \n",
      "       [-3.54107571,  0.13712896,  3.51870918, -1.29707146,  1.19438601],\n",
      "       [-1.71954191,  0.26545823, -1.95794499, -2.34598494,  1.84935164],\n",
      "       [ 1.02985048,  3.2780385 ,  2.27498722, -3.64058733, -3.00045824]], dtype=float32) \n",
      " decoder log variance: array([[-1.64134693, -0.96269464, -0.9417907 , -0.01352963, -0.05331238],\n",
      "       [ 0.11914162, -0.188813  , -0.38220456, -2.56708503, -0.40484327],\n",
      "       [-0.73616534, -0.20450281,  0.99326849, -0.11066894, -0.71033025],\n",
      "       ..., \n",
      "       [ 0.96302843, -0.52206212,  0.48302454, -1.66716492, -0.80785817],\n",
      "       [-0.25443342,  0.87971234,  0.23910587, -1.52785659,  1.24684811],\n",
      "       [ 0.93405384, -0.04766067,  0.16495645, -1.38499618,  0.20877965]], dtype=float32) \n",
      "\n",
      "kl loss: -17.467014, ce loss: 0.200273 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.930747, training loss: 17.667286\n",
      "epoch 4, minibatch 183/183, validation loss 17.715820\n",
      "test accuracy: 0.938283\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.9570415 , -1.66952848, -3.05064273,  5.09265995,  0.88557833],\n",
      "       [-2.59992695,  4.6048274 , -0.19866407, -3.47799635, -1.29358125],\n",
      "       [-0.63241655, -3.53406668,  2.19921756,  0.24342123,  1.73993933],\n",
      "       ..., \n",
      "       [-3.86321139,  0.20656043,  3.58537555, -1.5081718 ,  1.36516845],\n",
      "       [-1.62305534,  0.11031082, -2.01398969, -2.50841284,  2.20817471],\n",
      "       [ 1.4125073 ,  3.06328559,  2.27917743, -3.70214653, -3.16622519]], dtype=float32) \n",
      " decoder log variance: array([[-2.1452961 , -1.58573925, -1.66729474, -0.49371019, -0.62850899],\n",
      "       [-0.22209312, -0.45277122, -0.77543002, -2.89380383, -0.58526134],\n",
      "       [-0.93682766, -0.53280091,  0.6211217 , -0.29041627, -1.12005556],\n",
      "       ..., \n",
      "       [ 0.42008415, -0.99489379, -0.23419857, -2.14400172, -1.33493686],\n",
      "       [-0.40672588,  0.89358687, -0.02150278, -1.59044266,  1.2181344 ],\n",
      "       [ 0.74479806, -0.22194092, -0.24293454, -1.69113946, -0.04775126]], dtype=float32) \n",
      "\n",
      "kl loss: -16.660828, ce loss: 0.160445 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.944353, training loss: 16.821272\n",
      "epoch 5, minibatch 183/183, validation loss 16.952282\n",
      "test accuracy: 0.948081\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.12707949, -1.72268367, -3.14235735,  5.10463333,  0.54320127],\n",
      "       [-2.64287877,  4.66024733, -0.27616975, -3.4419477 , -1.40938306],\n",
      "       [-0.71156269, -3.54819441,  2.27871561,  0.17607144,  1.62915313],\n",
      "       ..., \n",
      "       [-4.06972742,  0.31711283,  3.39085817, -1.57288909,  1.25389016],\n",
      "       [-1.52365255, -0.03577755, -2.12526202, -2.53242612,  2.25148845],\n",
      "       [ 1.70432401,  2.85674381,  2.19321442, -3.61284089, -3.4891181 ]], dtype=float32) \n",
      " decoder log variance: array([[-2.53181648, -1.99710894, -2.06273031, -0.85078591, -1.15047276],\n",
      "       [-0.42987055, -0.67451739, -1.08061874, -3.03671432, -0.77510953],\n",
      "       [-1.12508476, -0.82766545,  0.27291498, -0.51753396, -1.49701989],\n",
      "       ..., \n",
      "       [-0.16173624, -1.43674266, -0.89467549, -2.57238388, -1.82457232],\n",
      "       [-0.50739747,  0.91838926, -0.12925529, -1.62295997,  1.18088889],\n",
      "       [ 0.56261259, -0.37710401, -0.59184998, -1.94082975, -0.26082793]], dtype=float32) \n",
      "\n",
      "kl loss: -15.979096, ce loss: 0.132117 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.953151, training loss: 16.111214\n",
      "epoch 6, minibatch 183/183, validation loss 16.348297\n",
      "test accuracy: 0.956061\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.13365364, -1.80441523, -2.99774265,  5.04971647,  0.35573095],\n",
      "       [-2.73935413,  4.7081871 , -0.13890497, -3.46924019, -1.4525367 ],\n",
      "       [-0.81815809, -3.48497844,  2.43278861,  0.07687564,  1.57507896],\n",
      "       ..., \n",
      "       [-4.29675436,  0.58022267,  3.29928541, -1.66994512,  1.17906916],\n",
      "       [-1.51138115, -0.19272064, -2.01510787, -2.58150291,  2.35697961],\n",
      "       [ 1.79348147,  2.7916944 ,  2.31304073, -3.58952045, -3.69405127]], dtype=float32) \n",
      " decoder log variance: array([[-2.77405548, -2.40503454, -2.2802341 , -1.19428706, -1.56662238],\n",
      "       [-0.64301151, -0.97273225, -1.3233968 , -3.24218297, -0.89721501],\n",
      "       [-1.3752867 , -1.19617021,  0.06305054, -0.80213892, -1.79500175],\n",
      "       ..., \n",
      "       [-0.6501568 , -1.90985084, -1.36191821, -2.96623802, -2.26686287],\n",
      "       [-0.62934119,  0.9036243 , -0.12862398, -1.63701558,  1.27158272],\n",
      "       [ 0.38424674, -0.60636514, -0.78427494, -2.11887789, -0.42307103]], dtype=float32) \n",
      "\n",
      "kl loss: -15.343906, ce loss: 0.115905 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.959126, training loss: 15.459809\n",
      "epoch 7, minibatch 183/183, validation loss 15.812598\n",
      "test accuracy: 0.961010\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.24489021, -1.93257797, -2.94542122,  5.01737499,  0.32537106],\n",
      "       [-2.68854976,  4.66044474, -0.03569385, -3.46226501, -1.43017137],\n",
      "       [-0.78948307, -3.47223473,  2.51036859,  0.02763621,  1.59839368],\n",
      "       ..., \n",
      "       [-4.39629793,  0.70490456,  3.22679234, -1.70316887,  1.26161909],\n",
      "       [-1.30766141, -0.40240693, -1.94610083, -2.59740758,  2.48694611],\n",
      "       [ 1.93103242,  2.65621781,  2.40046859, -3.51857901, -3.72884011]], dtype=float32) \n",
      " decoder log variance: array([[-2.97368145, -2.7062397 , -2.48587108, -1.35465872, -1.94748306],\n",
      "       [-0.75716507, -1.12077773, -1.51218534, -3.30306411, -1.03665793],\n",
      "       [-1.66579187, -1.42610145, -0.16685535, -1.02775955, -2.07703304],\n",
      "       ..., \n",
      "       [-1.0979563 , -2.18104267, -1.76676536, -3.26990819, -2.65116596],\n",
      "       [-0.68774951,  0.96124399, -0.15766406, -1.61199045,  1.3512907 ],\n",
      "       [ 0.29852137, -0.6551556 , -0.95694423, -2.30017829, -0.56757629]], dtype=float32) \n",
      "\n",
      "kl loss: -14.828491, ce loss: 0.108399 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.963971, training loss: 14.936890\n",
      "epoch 8, minibatch 183/183, validation loss 15.343834\n",
      "test accuracy: 0.962525\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.25603533, -1.97975385, -2.88231373,  5.01260567,  0.30637863],\n",
      "       [-2.69267726,  4.69244957,  0.04668307, -3.48125625, -1.48567379],\n",
      "       [-0.79630476, -3.45269108,  2.59800386, -0.01040335,  1.57433176],\n",
      "       ..., \n",
      "       [-4.540977  ,  0.80482972,  3.22765303, -1.74248612,  1.25808418],\n",
      "       [-1.19989598, -0.53774083, -1.8793962 , -2.62865376,  2.50069046],\n",
      "       [ 1.9732846 ,  2.61031485,  2.48256183, -3.50809741, -3.80612063]], dtype=float32) \n",
      " decoder log variance: array([[-3.15688086, -2.99974394, -2.70181799, -1.51398337, -2.20802236],\n",
      "       [-0.98466873, -1.3596611 , -1.79370904, -3.44271445, -1.16100538],\n",
      "       [-1.96620607, -1.75168967, -0.46785775, -1.27157617, -2.29761624],\n",
      "       ..., \n",
      "       [-1.50973952, -2.50448656, -2.08835649, -3.35033894, -2.93992019],\n",
      "       [-0.8001408 ,  0.94455791, -0.19517191, -1.69885337,  1.45080662],\n",
      "       [ 0.14814138, -0.79461724, -1.14632475, -2.40879655, -0.66962856]], dtype=float32) \n",
      "\n",
      "kl loss: -14.410589, ce loss: 0.095663 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.967869, training loss: 14.506252\n",
      "epoch 9, minibatch 183/183, validation loss 14.988935\n",
      "test accuracy: 0.963535\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.21501493, -1.98735738, -2.86465192,  5.00699854,  0.27089781],\n",
      "       [-2.71142054,  4.73691988,  0.04602308, -3.48951483, -1.57787204],\n",
      "       [-0.82745194, -3.43593597,  2.62911129, -0.08062793,  1.52232993],\n",
      "       ..., \n",
      "       [-4.67288589,  0.90323925,  3.17182565, -1.80595994,  1.23389232],\n",
      "       [-1.15994978, -0.60340565, -1.87781453, -2.61973834,  2.46140194],\n",
      "       [ 2.00546288,  2.60110688,  2.48902225, -3.52908683, -3.90982461]], dtype=float32) \n",
      " decoder log variance: array([[-3.26565981, -3.16251326, -2.94836044, -1.83865285, -2.4397428 ],\n",
      "       [-1.16691864, -1.45226765, -2.07469678, -3.72718382, -1.28329539],\n",
      "       [-2.24424314, -1.9832201 , -0.77334964, -1.5714345 , -2.5055573 ],\n",
      "       ..., \n",
      "       [-1.84895599, -2.66932821, -2.36960196, -3.49969745, -3.15695262],\n",
      "       [-0.87541837,  1.05730796, -0.26927298, -1.86301625,  1.56647778],\n",
      "       [-0.02948748, -0.82165384, -1.39267015, -2.64118028, -0.76300067]], dtype=float32) \n",
      "\n",
      "kl loss: -14.002282, ce loss: 0.080872 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.971148, training loss: 14.083155\n",
      "epoch 10, minibatch 183/183, validation loss 14.741093\n",
      "test accuracy: 0.965556\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.18917179, -1.99795842, -2.89660525,  4.99502325,  0.28810799],\n",
      "       [-2.71759129,  4.77615643,  0.02151109, -3.48108172, -1.58815873],\n",
      "       [-0.83794892, -3.42683673,  2.64029384, -0.10319036,  1.50995302],\n",
      "       ..., \n",
      "       [-4.76443243,  0.98638672,  3.0734942 , -1.82909894,  1.24491036],\n",
      "       [-1.11758256, -0.66383171, -1.92201614, -2.61804795,  2.50373363],\n",
      "       [ 2.02625704,  2.5992434 ,  2.46504211, -3.51320481, -3.92521691]], dtype=float32) \n",
      " decoder log variance: array([[-3.4246769 , -3.23918509, -3.08154058, -2.00966597, -2.6939702 ],\n",
      "       [-1.40204513, -1.53297198, -2.33610392, -3.84119487, -1.41153705],\n",
      "       [-2.58426356, -2.18058681, -1.03521025, -1.78706312, -2.71024752],\n",
      "       ..., \n",
      "       [-2.16079021, -2.71604586, -2.51686978, -3.48339462, -3.33572078],\n",
      "       [-1.01632762,  1.13293183, -0.31479049, -1.94659877,  1.62057257],\n",
      "       [-0.21320672, -0.80999416, -1.56415284, -2.74834323, -0.85332674]], dtype=float32) \n",
      "\n",
      "kl loss: -13.682658, ce loss: 0.073696 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.974262, training loss: 13.756354\n",
      "epoch 11, minibatch 183/183, validation loss 14.527830\n",
      "test accuracy: 0.968182\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.16408682, -2.02360439, -2.8920157 ,  4.98466396,  0.30579773],\n",
      "       [-2.71163988,  4.78474712,  0.03201491, -3.4708066 , -1.60256684],\n",
      "       [-0.86064142, -3.43618417,  2.68273759, -0.10516527,  1.50869954],\n",
      "       ..., \n",
      "       [-4.83694887,  1.02159154,  3.00816846, -1.82207119,  1.27096701],\n",
      "       [-1.08122337, -0.75894141, -1.91693723, -2.63367081,  2.51948333],\n",
      "       [ 2.03878999,  2.59102368,  2.46521354, -3.49352407, -3.93113637]], dtype=float32) \n",
      " decoder log variance: array([[-3.57072568, -3.37242246, -3.23990607, -2.19458175, -2.92129588],\n",
      "       [-1.54692197, -1.69175828, -2.58979869, -4.0090003 , -1.59650147],\n",
      "       [-2.80037832, -2.46375322, -1.27163494, -2.0497539 , -2.94301462],\n",
      "       ..., \n",
      "       [-2.36778736, -2.81217146, -2.61842847, -3.47644114, -3.47344017],\n",
      "       [-1.0613389 ,  1.14895785, -0.40424246, -2.11661243,  1.57641268],\n",
      "       [-0.32509831, -0.91558284, -1.77053177, -2.91584539, -0.94852787]], dtype=float32) \n",
      "\n",
      "kl loss: -13.386056, ce loss: 0.078380 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.977432, training loss: 13.464436\n",
      "epoch 12, minibatch 183/183, validation loss 14.329386\n",
      "test accuracy: 0.969596\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.12790442, -2.02735519, -2.87466478,  4.98202801,  0.33789095],\n",
      "       [-2.74614978,  4.81923103,  0.06162763, -3.4645977 , -1.60673141],\n",
      "       [-0.88423657, -3.43424678,  2.71859288, -0.12594952,  1.50496876],\n",
      "       ..., \n",
      "       [-4.89486599,  1.05009687,  2.97357941, -1.82019722,  1.27416801],\n",
      "       [-1.05815673, -0.81373674, -1.89882803, -2.62948561,  2.52526665],\n",
      "       [ 2.05720282,  2.57132292,  2.481179  , -3.47296143, -3.94011831]], dtype=float32) \n",
      " decoder log variance: array([[-3.69262314, -3.4768548 , -3.31937599, -2.35917377, -3.12234259],\n",
      "       [-1.72546482, -1.76299751, -2.79602981, -4.19537497, -1.7012502 ],\n",
      "       [-3.05147862, -2.64845896, -1.50296462, -2.27745891, -3.07895422],\n",
      "       ..., \n",
      "       [-2.53027153, -2.79187155, -2.63038468, -3.4662571 , -3.52660322],\n",
      "       [-1.11522901,  1.1836822 , -0.48215887, -2.25056553,  1.65436423],\n",
      "       [-0.48285639, -0.94264477, -1.91182053, -3.08942866, -1.00820982]], dtype=float32) \n",
      "\n",
      "kl loss: -13.154160, ce loss: 0.073283 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.980146, training loss: 13.227444\n",
      "epoch 13, minibatch 183/183, validation loss 14.213338\n",
      "test accuracy: 0.971111\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.08119011, -2.15708613, -2.80948234,  4.98273993,  0.3618705 ],\n",
      "       [-2.76209998,  4.7024684 ,  0.12943214, -3.45325708, -1.59267735],\n",
      "       [-0.92536092, -3.51487207,  2.81705952, -0.10855561,  1.50013816],\n",
      "       ..., \n",
      "       [-4.94721365,  0.96129072,  3.03645349, -1.76025963,  1.29111922],\n",
      "       [-1.04384017, -1.05739188, -1.7966212 , -2.65163088,  2.53959537],\n",
      "       [ 2.04156995,  2.48004913,  2.54864669, -3.41805983, -3.94495535]], dtype=float32) \n",
      " decoder log variance: array([[-3.70836997, -3.51728511, -3.27823544, -2.41473269, -3.28788829],\n",
      "       [-1.81232643, -1.88323021, -2.92796993, -4.21285629, -1.8711561 ],\n",
      "       [-3.12270737, -2.8521266 , -1.66950607, -2.45655513, -3.37267637],\n",
      "       ..., \n",
      "       [-2.55245829, -2.77776933, -2.63002515, -3.41264653, -3.69184923],\n",
      "       [-1.14099455,  1.15640759, -0.55554748, -2.33509946,  1.57672179],\n",
      "       [-0.49718755, -1.05197954, -2.04195213, -3.18363166, -1.14261889]], dtype=float32) \n",
      "\n",
      "kl loss: -12.966226, ce loss: 0.053749 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.981821, training loss: 13.019974\n",
      "epoch 14, minibatch 183/183, validation loss 14.144108\n",
      "test accuracy: 0.973434\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99620295, -2.17217541, -2.87679267,  4.95464849,  0.37339023],\n",
      "       [-2.82738781,  4.70103168,  0.12518133, -3.46309471, -1.63999903],\n",
      "       [-1.02650046, -3.4917531 ,  2.76431298, -0.1483971 ,  1.49719572],\n",
      "       ..., \n",
      "       [-5.01662636,  0.99185801,  2.92148042, -1.76365471,  1.24410224],\n",
      "       [-1.07237661, -1.11676145, -1.83336508, -2.67890334,  2.46328354],\n",
      "       [ 2.02871966,  2.45743442,  2.4901135 , -3.42188644, -4.00600147]], dtype=float32) \n",
      " decoder log variance: array([[-3.67781019, -3.53584528, -3.37607288, -2.55070019, -3.44891524],\n",
      "       [-1.8250463 , -1.92153919, -3.18521452, -4.28380442, -2.00282741],\n",
      "       [-3.15456486, -2.96279788, -1.89262748, -2.7259655 , -3.54499435],\n",
      "       ..., \n",
      "       [-2.57394671, -2.80101037, -2.72371006, -3.46925068, -3.90753794],\n",
      "       [-1.12391341,  1.16479683, -0.77467859, -2.40660763,  1.54656529],\n",
      "       [-0.5519582 , -1.05544353, -2.28571177, -3.32135987, -1.27682269]], dtype=float32) \n",
      "\n",
      "kl loss: -12.878499, ce loss: 0.054020 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.984153, training loss: 12.932519\n",
      "epoch 15, minibatch 183/183, validation loss 13.841035\n",
      "test accuracy: 0.974141\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.00025606, -2.17365813, -2.83376098,  4.97995663,  0.3844676 ],\n",
      "       [-2.83790874,  4.72393322,  0.14575005, -3.45422053, -1.62726784],\n",
      "       [-1.04824436, -3.47441554,  2.82982421, -0.14730741,  1.50297666],\n",
      "       ..., \n",
      "       [-5.03320217,  1.03255963,  2.95416093, -1.72384632,  1.23933315],\n",
      "       [-1.037413  , -1.12903738, -1.83319068, -2.67833042,  2.47420406],\n",
      "       [ 2.03377366,  2.49370861,  2.49576712, -3.38294864, -4.00999594]], dtype=float32) \n",
      " decoder log variance: array([[-3.81894326, -3.72345161, -3.45277452, -2.6374712 , -3.55154991],\n",
      "       [-1.90804768, -2.10656357, -3.16695547, -4.35532093, -2.00765038],\n",
      "       [-3.31237912, -3.21614885, -2.00067663, -2.88402987, -3.5927937 ],\n",
      "       ..., \n",
      "       [-2.61101651, -2.8674624 , -2.65521741, -3.37950349, -3.85565257],\n",
      "       [-1.20054114,  1.08023286, -0.79868191, -2.49920344,  1.62033081],\n",
      "       [-0.57720959, -1.17466068, -2.29320145, -3.39786053, -1.21136558]], dtype=float32) \n",
      "\n",
      "kl loss: -12.710340, ce loss: 0.054638 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.986011, training loss: 12.764977\n",
      "epoch 16, minibatch 183/183, validation loss 13.760976\n",
      "test accuracy: 0.973434\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.00863981, -2.16503596, -2.85928607,  4.93998146,  0.40297785],\n",
      "       [-2.83785605,  4.7374053 ,  0.14233109, -3.45583606, -1.60991848],\n",
      "       [-1.05181062, -3.47571993,  2.84192204, -0.17554717,  1.51205432],\n",
      "       ..., \n",
      "       [-5.06076002,  1.06176651,  2.93651772, -1.74302387,  1.22929943],\n",
      "       [-1.01006722, -1.11154354, -1.83777857, -2.70338511,  2.44642806],\n",
      "       [ 2.02401805,  2.51120281,  2.51907706, -3.39346099, -4.00953436]], dtype=float32) \n",
      " decoder log variance: array([[-3.96217728, -3.87126422, -3.57702827, -2.75391698, -3.67226481],\n",
      "       [-2.048136  , -2.2524178 , -3.32294226, -4.41009569, -2.12411499],\n",
      "       [-3.46405697, -3.38023353, -2.16683507, -3.07057428, -3.67281938],\n",
      "       ..., \n",
      "       [-2.66504622, -2.8230207 , -2.63217592, -3.30534863, -3.83776069],\n",
      "       [-1.23346591,  1.08524621, -0.82518184, -2.5134933 ,  1.67764521],\n",
      "       [-0.69391531, -1.29748821, -2.4173789 , -3.48422647, -1.2340709 ]], dtype=float32) \n",
      "\n",
      "kl loss: -12.427171, ce loss: 0.041215 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.987231, training loss: 12.468386\n",
      "epoch 17, minibatch 183/183, validation loss 13.695547\n",
      "test accuracy: 0.975253\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.00986195, -2.16792297, -2.85864973,  4.94952631,  0.4023807 ],\n",
      "       [-2.83891106,  4.72744894,  0.15172073, -3.45913172, -1.6060549 ],\n",
      "       [-1.05605793, -3.4739089 ,  2.87194824, -0.17323478,  1.50796783],\n",
      "       ..., \n",
      "       [-5.0592947 ,  1.08877051,  2.93763399, -1.72844982,  1.19751763],\n",
      "       [-0.97607869, -1.15879166, -1.8367883 , -2.70744205,  2.42718124],\n",
      "       [ 2.05623317,  2.51029468,  2.5398531 , -3.39017272, -4.03918695]], dtype=float32) \n",
      " decoder log variance: array([[-4.00351572, -3.85881925, -3.5925684 , -2.85148311, -3.73732042],\n",
      "       [-2.16437888, -2.34669995, -3.37903309, -4.4912796 , -2.18929863],\n",
      "       [-3.60871291, -3.46572137, -2.27691889, -3.20368218, -3.80434465],\n",
      "       ..., \n",
      "       [-2.68613744, -2.65865993, -2.52445769, -3.15304351, -3.79302216],\n",
      "       [-1.35014689,  1.04333353, -0.84104323, -2.58359551,  1.70514429],\n",
      "       [-0.84317952, -1.34373164, -2.49758911, -3.54237819, -1.26895165]], dtype=float32) \n",
      "\n",
      "kl loss: -12.344035, ce loss: 0.044775 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.988233, training loss: 12.388810\n",
      "epoch 18, minibatch 183/183, validation loss 13.655570\n",
      "test accuracy: 0.974747\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.98719668, -2.1659956 , -2.93034577,  5.00212193,  0.40654364],\n",
      "       [-2.84612298,  4.75514603,  0.10670354, -3.39754891, -1.60577464],\n",
      "       [-1.10744989, -3.45056605,  2.851861  , -0.11538073,  1.51288855],\n",
      "       ..., \n",
      "       [-5.06981802,  1.08940208,  2.90063834, -1.72980452,  1.18961811],\n",
      "       [-0.95869094, -1.13698757, -1.92293501, -2.66139054,  2.42106605],\n",
      "       [ 2.07067609,  2.50996399,  2.47821832, -3.36943722, -4.05533457]], dtype=float32) \n",
      " decoder log variance: array([[-3.94718075, -3.95280051, -3.62038684, -2.98481894, -3.85052824],\n",
      "       [-2.16064382, -2.40377808, -3.57519746, -4.37581921, -2.33525515],\n",
      "       [-3.5664649 , -3.7317214 , -2.43806887, -3.26163673, -3.97559571],\n",
      "       ..., \n",
      "       [-2.58512902, -2.77402115, -2.45266891, -2.7443676 , -3.82347989],\n",
      "       [-1.23214412,  0.99195945, -0.99551123, -2.6897583 ,  1.68908453],\n",
      "       [-0.81576389, -1.41113293, -2.50416803, -3.37033844, -1.3124845 ]], dtype=float32) \n",
      "\n",
      "kl loss: -12.355358, ce loss: 0.036867 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.990182, training loss: 12.392224\n",
      "epoch 19, minibatch 183/183, validation loss 13.621089\n",
      "test accuracy: 0.975253\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.04095984, -2.11458993, -2.93823624,  4.95155334,  0.5241093 ],\n",
      "       [-2.86533499,  4.81609869,  0.09624952, -3.42609978, -1.50542474],\n",
      "       [-1.13578677, -3.40295076,  2.86804724, -0.14915423,  1.66024399],\n",
      "       ..., \n",
      "       [-5.13302708,  1.20593345,  2.88592029, -1.75602937,  1.37245095],\n",
      "       [-0.92136818, -1.10337675, -1.9375    , -2.7212491 ,  2.53132439],\n",
      "       [ 2.07155824,  2.57401991,  2.47480392, -3.40096569, -3.92319131]], dtype=float32) \n",
      " decoder log variance: array([[-4.07890606, -4.09557629, -3.65867019, -3.10186386, -3.86189246],\n",
      "       [-2.48736978, -2.5532639 , -3.68155527, -4.83300018, -2.36127591],\n",
      "       [-3.69567871, -3.81962562, -2.46589518, -3.53853941, -3.82405567],\n",
      "       ..., \n",
      "       [-2.6483252 , -2.73473191, -2.39233685, -2.93028855, -3.52302384],\n",
      "       [-1.54507267,  0.9138357 , -1.07405066, -3.01919746,  1.72907495],\n",
      "       [-1.11581326, -1.49197745, -2.57614923, -3.77191734, -1.32332385]], dtype=float32) \n",
      "\n",
      "kl loss: -12.180517, ce loss: 0.031252 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.991621, training loss: 12.211769\n",
      "epoch 20, minibatch 183/183, validation loss 13.614882\n",
      "test accuracy: 0.976667\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99374175, -2.15245724, -2.86932302,  4.96309662,  0.50736749],\n",
      "       [-2.90678501,  4.80374765,  0.17678587, -3.45086646, -1.53174794],\n",
      "       [-1.1900326 , -3.4263463 ,  2.9282341 , -0.17248678,  1.63727641],\n",
      "       ..., \n",
      "       [-5.17863035,  1.20224154,  2.91648555, -1.76988447,  1.29605293],\n",
      "       [-0.9404183 , -1.12884605, -1.86491215, -2.74151111,  2.5196023 ],\n",
      "       [ 2.03671646,  2.55750728,  2.54233336, -3.39872813, -4.00471401]], dtype=float32) \n",
      " decoder log variance: array([[-4.04691362, -4.00999069, -3.71515632, -3.17516255, -3.99421453],\n",
      "       [-2.43848276, -2.57267141, -3.91765165, -4.92791176, -2.64915466],\n",
      "       [-3.69450164, -3.92754889, -2.65624547, -3.68944001, -4.0256381 ],\n",
      "       ..., \n",
      "       [-2.5413456 , -2.61882973, -2.58434224, -3.02307534, -3.60362625],\n",
      "       [-1.38837945,  0.95969033, -1.15145564, -3.00970817,  1.65572095],\n",
      "       [-1.02913618, -1.46696973, -2.72056293, -3.85921693, -1.42468929]], dtype=float32) \n",
      "\n",
      "kl loss: -11.994159, ce loss: 0.028595 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.992077, training loss: 12.022754\n",
      "epoch 21, minibatch 183/183, validation loss 13.538941\n",
      "test accuracy: 0.976566\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99130893, -2.13064981, -2.82245827,  4.98788977,  0.5068894 ],\n",
      "       [-2.8832314 ,  4.81188965,  0.1878946 , -3.40435076, -1.5422765 ],\n",
      "       [-1.19895613, -3.42248249,  2.9839282 , -0.12856077,  1.63007188],\n",
      "       ..., \n",
      "       [-5.17025948,  1.22049797,  2.94651008, -1.7594763 ,  1.29084539],\n",
      "       [-0.90188742, -1.18953204, -1.82104361, -2.70205879,  2.49883294],\n",
      "       [ 2.05166602,  2.59003639,  2.5650773 , -3.3824017 , -4.01708794]], dtype=float32) \n",
      " decoder log variance: array([[-4.22028732, -4.20974541, -3.82843018, -3.17095709, -4.12504959],\n",
      "       [-2.61378098, -2.79736567, -4.04926968, -4.86072636, -2.78131032],\n",
      "       [-3.85719848, -4.08669329, -2.75104737, -3.66063738, -4.2019496 ],\n",
      "       ..., \n",
      "       [-2.65006423, -2.68100524, -2.57858562, -2.73046112, -3.68613195],\n",
      "       [-1.38405395,  0.7744447 , -1.23442078, -2.97708797,  1.61650681],\n",
      "       [-1.12672412, -1.69252801, -2.78702712, -3.74503088, -1.47070122]], dtype=float32) \n",
      "\n",
      "kl loss: -11.880280, ce loss: 0.027834 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.993333, training loss: 11.908113\n",
      "epoch 22, minibatch 183/183, validation loss 13.480616\n",
      "test accuracy: 0.977677\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.01318932, -2.08523941, -2.80585146,  4.98810577,  0.49697098],\n",
      "       [-2.87751889,  4.84778833,  0.1967022 , -3.42808366, -1.57115293],\n",
      "       [-1.1855458 , -3.38158584,  3.01427484, -0.12183709,  1.59778428],\n",
      "       ..., \n",
      "       [-5.16832447,  1.28216553,  2.95803213, -1.72516251,  1.25160587],\n",
      "       [-0.8565284 , -1.19144046, -1.80332208, -2.72214961,  2.44838262],\n",
      "       [ 2.06968284,  2.60966778,  2.57474589, -3.36394191, -4.0627656 ]], dtype=float32) \n",
      " decoder log variance: array([[-4.2606411 , -4.23765945, -3.89245105, -3.20065594, -4.17840672],\n",
      "       [-2.76610804, -2.86655021, -4.13096714, -4.98933506, -2.95036602],\n",
      "       [-4.10540295, -4.12830687, -2.87963581, -3.73787594, -4.42202663],\n",
      "       ..., \n",
      "       [-2.72776055, -2.54239607, -2.59198356, -2.85857701, -3.79691458],\n",
      "       [-1.41837132,  0.76470929, -1.30704761, -3.07914424,  1.52679634],\n",
      "       [-1.25604784, -1.7355653 , -2.82108927, -3.84799671, -1.60266793]], dtype=float32) \n",
      "\n",
      "kl loss: -11.660373, ce loss: 0.026810 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.993989, training loss: 11.687184\n",
      "epoch 23, minibatch 183/183, validation loss 13.531839\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99290371, -2.11723781, -2.81768775,  4.97430944,  0.49016523],\n",
      "       [-2.90825224,  4.84943771,  0.18977261, -3.43847823, -1.58613551],\n",
      "       [-1.21101487, -3.39479327,  3.00628495, -0.14957467,  1.60210752],\n",
      "       ..., \n",
      "       [-5.1537261 ,  1.25592589,  2.93720698, -1.75318217,  1.2327733 ],\n",
      "       [-0.89010012, -1.20365238, -1.82092726, -2.7509315 ,  2.42814994],\n",
      "       [ 2.0473249 ,  2.59243608,  2.5804832 , -3.3644731 , -4.07004404]], dtype=float32) \n",
      " decoder log variance: array([[-4.35408545, -4.38544464, -3.91144848, -3.43954515, -4.30399895],\n",
      "       [-2.85503983, -2.97532082, -4.28847742, -5.13583231, -3.11251187],\n",
      "       [-4.09236956, -4.27513933, -2.95660138, -3.98304272, -4.5753994 ],\n",
      "       ..., \n",
      "       [-2.69101524, -2.63604283, -2.65790749, -2.95839667, -3.8862741 ],\n",
      "       [-1.39320838,  0.78464502, -1.29247391, -3.11002851,  1.52867627],\n",
      "       [-1.2214849 , -1.78646421, -2.82494092, -3.95296741, -1.68644512]], dtype=float32) \n",
      "\n",
      "kl loss: -11.392862, ce loss: 0.021027 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.994772, training loss: 11.413888\n",
      "epoch 24, minibatch 183/183, validation loss 13.596509\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99256372, -2.12913322, -2.82547879,  4.97266388,  0.50078124],\n",
      "       [-2.91041517,  4.83903027,  0.17615056, -3.44303083, -1.59178197],\n",
      "       [-1.20714319, -3.40178847,  3.02080655, -0.15880182,  1.58671844],\n",
      "       ..., \n",
      "       [-5.14493418,  1.20050812,  2.94950891, -1.74499655,  1.21610582],\n",
      "       [-0.88359648, -1.20125186, -1.81906271, -2.76515937,  2.41193318],\n",
      "       [ 2.0681963 ,  2.55099821,  2.58103013, -3.37414789, -4.09028864]], dtype=float32) \n",
      " decoder log variance: array([[-4.35663605, -4.56608629, -4.03142452, -3.51695895, -4.3845582 ],\n",
      "       [-2.87530875, -3.08768535, -4.3859396 , -5.16100502, -3.16779804],\n",
      "       [-4.10611343, -4.48843384, -3.03568029, -4.05843306, -4.67862463],\n",
      "       ..., \n",
      "       [-2.60833812, -2.74033904, -2.68074298, -3.01800466, -3.8744669 ],\n",
      "       [-1.3989836 ,  0.73510605, -1.34183633, -3.15079427,  1.57368541],\n",
      "       [-1.16795182, -1.86777902, -2.86137867, -4.03316164, -1.66328859]], dtype=float32) \n",
      "\n",
      "kl loss: -11.246490, ce loss: 0.025984 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.995319, training loss: 11.272474\n",
      "epoch 25, minibatch 183/183, validation loss 13.531899\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.97350073, -2.11579704, -2.82661295,  4.96574783,  0.52732348],\n",
      "       [-2.92693019,  4.84149408,  0.18600455, -3.42910314, -1.59290445],\n",
      "       [-1.20157444, -3.40220666,  3.03710055, -0.14299147,  1.58358252],\n",
      "       ..., \n",
      "       [-5.16673565,  1.22142959,  2.94689417, -1.75420892,  1.22859788],\n",
      "       [-0.93642616, -1.18170142, -1.80403614, -2.7657845 ,  2.4402976 ],\n",
      "       [ 2.04032874,  2.56118727,  2.58789444, -3.37763476, -4.07191896]], dtype=float32) \n",
      " decoder log variance: array([[-4.21995878, -4.69836903, -4.04776573, -3.53981853, -4.41383219],\n",
      "       [-2.90459585, -3.26434565, -4.51654196, -5.16678286, -3.20804119],\n",
      "       [-4.01523399, -4.58937311, -3.11473441, -4.15281677, -4.62741184],\n",
      "       ..., \n",
      "       [-2.29535389, -2.67155313, -2.54232526, -2.78014469, -3.62325144],\n",
      "       [-1.24640989,  0.6934616 , -1.42609835, -3.16553617,  1.70283008],\n",
      "       [-1.12699234, -2.02061558, -2.90309501, -3.99581361, -1.59608316]], dtype=float32) \n",
      "\n",
      "kl loss: -11.244457, ce loss: 0.017811 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.995574, training loss: 11.262268\n",
      "epoch 26, minibatch 183/183, validation loss 13.530092\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.98815536, -2.12911749, -2.82784009,  4.98560905,  0.52628767],\n",
      "       [-2.91284132,  4.83720779,  0.19056918, -3.42516184, -1.60442007],\n",
      "       [-1.17572224, -3.40682745,  3.0372839 , -0.12034579,  1.57485127],\n",
      "       ..., \n",
      "       [-5.12987661,  1.17551899,  2.95078206, -1.74526668,  1.21617675],\n",
      "       [-0.88127565, -1.19554722, -1.7973088 , -2.76785088,  2.38279366],\n",
      "       [ 2.06866002,  2.53170943,  2.58881903, -3.36742878, -4.08427811]], dtype=float32) \n",
      " decoder log variance: array([[-4.39800406, -4.77687788, -4.10642147, -3.56456494, -4.51102304],\n",
      "       [-3.1254611 , -3.37926459, -4.63826132, -5.29643488, -3.31431508],\n",
      "       [-4.19293451, -4.68412256, -3.14857841, -4.17300272, -4.70517397],\n",
      "       ..., \n",
      "       [-2.46602559, -2.69040132, -2.53082991, -2.75406957, -3.75690365],\n",
      "       [-1.35722804,  0.70348549, -1.48856795, -3.29088616,  1.68169796],\n",
      "       [-1.29724789, -2.12034965, -2.95188093, -4.05019093, -1.6880542 ]], dtype=float32) \n",
      "\n",
      "kl loss: -11.090509, ce loss: 0.016455 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.996612, training loss: 11.106963\n",
      "epoch 27, minibatch 183/183, validation loss 13.564089\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99342418, -2.14327383, -2.81247163,  4.97548008,  0.52012563],\n",
      "       [-2.93042302,  4.85337543,  0.19954577, -3.45434594, -1.609532  ],\n",
      "       [-1.17368329, -3.41230035,  3.05916619, -0.15288317,  1.56940079],\n",
      "       ..., \n",
      "       [-5.14978361,  1.19081271,  2.9597702 , -1.75270689,  1.21067429],\n",
      "       [-0.87106299, -1.18702841, -1.7744894 , -2.78780985,  2.34115672],\n",
      "       [ 2.05543303,  2.55605555,  2.60203719, -3.36510897, -4.09193277]], dtype=float32) \n",
      " decoder log variance: array([[-4.46337891, -4.82743979, -4.17551041, -3.66370225, -4.59192562],\n",
      "       [-3.30300593, -3.44768429, -4.69552374, -5.28153038, -3.39679646],\n",
      "       [-4.29123163, -4.69097614, -3.20131397, -4.23941565, -4.77003336],\n",
      "       ..., \n",
      "       [-2.44123793, -2.51770878, -2.39713979, -2.67630076, -3.6418128 ],\n",
      "       [-1.35461485,  0.73845774, -1.48355544, -3.35952187,  1.68438554],\n",
      "       [-1.44598854, -2.12866902, -3.00753736, -4.15023804, -1.76341748]], dtype=float32) \n",
      "\n",
      "kl loss: -10.961939, ce loss: 0.013106 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.996412, training loss: 10.975044\n",
      "epoch 28, minibatch 183/183, validation loss 13.585215\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99742222, -2.14063692, -2.81692314,  4.94512415,  0.5245344 ],\n",
      "       [-2.90646601,  4.85176277,  0.18792215, -3.4460361 , -1.60788596],\n",
      "       [-1.15242279, -3.40408206,  3.04741502, -0.1454813 ,  1.57366467],\n",
      "       ..., \n",
      "       [-5.08787203,  1.18407452,  2.97308731, -1.74725294,  1.18742144],\n",
      "       [-0.81995964, -1.19119418, -1.82127738, -2.81699514,  2.33229232],\n",
      "       [ 2.12277627,  2.51497865,  2.63032937, -3.34769869, -4.13803768]], dtype=float32) \n",
      " decoder log variance: array([[-4.59211588, -4.8875227 , -4.35477495, -3.84367418, -4.68157768],\n",
      "       [-3.3977921 , -3.47562408, -4.76146841, -5.37918234, -3.47415137],\n",
      "       [-4.34727669, -4.78400135, -3.27357626, -4.24190044, -4.94020653],\n",
      "       ..., \n",
      "       [-2.55524802, -2.44205523, -2.36823249, -2.72108722, -3.75989819],\n",
      "       [-1.32610798,  0.77933943, -1.53451097, -3.40160537,  1.66325247],\n",
      "       [-1.52805197, -2.09748721, -3.01228905, -4.1430254 , -1.8075949 ]], dtype=float32) \n",
      "\n",
      "kl loss: -10.898395, ce loss: 0.015790 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.997177, training loss: 10.914185\n",
      "epoch 29, minibatch 183/183, validation loss 13.615799\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.94292545, -2.14115357, -2.75692558,  4.96667242,  0.57015431],\n",
      "       [-3.00265098,  4.87477064,  0.21332912, -3.45228553, -1.57764471],\n",
      "       [-1.20100141, -3.38790512,  3.07239985, -0.13569281,  1.61777639],\n",
      "       ..., \n",
      "       [-5.11286783,  1.17981017,  2.97875404, -1.74943507,  1.25017655],\n",
      "       [-0.90876663, -1.18242681, -1.76286817, -2.81033158,  2.36293316],\n",
      "       [ 2.05421138,  2.55711865,  2.61603022, -3.34609985, -4.06808901]], dtype=float32) \n",
      " decoder log variance: array([[-4.51419926, -4.90635395, -4.44592476, -3.97164273, -4.8042655 ],\n",
      "       [-3.39342642, -3.45772886, -4.73889303, -5.33744431, -3.43140388],\n",
      "       [-4.16328335, -4.77457428, -3.4338789 , -4.43510199, -4.9131875 ],\n",
      "       ..., \n",
      "       [-2.2544632 , -2.30935645, -2.41312766, -2.72736716, -3.76257014],\n",
      "       [-1.15270329,  0.89345008, -1.6401577 , -3.37628531,  1.84943438],\n",
      "       [-1.51332712, -2.12428546, -3.19559264, -4.23671818, -1.81093812]], dtype=float32) \n",
      "\n",
      "kl loss: -11.050059, ce loss: 0.014238 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.997523, training loss: 11.064296\n",
      "epoch 30, minibatch 183/183, validation loss 13.620831\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.96597648, -2.14837956, -2.80760002,  4.96615076,  0.55846417],\n",
      "       [-2.96408677,  4.86976767,  0.19339806, -3.41983438, -1.5836997 ],\n",
      "       [-1.18450463, -3.39571166,  3.06985593, -0.11307814,  1.58961523],\n",
      "       ..., \n",
      "       [-5.13299942,  1.21008956,  3.00044322, -1.71217549,  1.1904012 ],\n",
      "       [-0.84542054, -1.21527553, -1.77767944, -2.80867362,  2.32246995],\n",
      "       [ 2.02705717,  2.57451773,  2.61937714, -3.33614182, -4.07863331]], dtype=float32) \n",
      " decoder log variance: array([[-4.63584852, -4.96613932, -4.41580248, -3.77699375, -4.74267483],\n",
      "       [-3.70677495, -3.69005203, -4.90696859, -5.34193993, -3.62809157],\n",
      "       [-4.53074884, -4.92272711, -3.48440671, -4.38758612, -4.99889565],\n",
      "       ..., \n",
      "       [-2.62123513, -2.31838822, -2.5218327 , -2.66533923, -3.83597374],\n",
      "       [-1.38702118,  0.71530998, -1.64872742, -3.37767172,  1.68051827],\n",
      "       [-1.83063781, -2.22899103, -3.19534183, -4.1566143 , -1.88698137]], dtype=float32) \n",
      "\n",
      "kl loss: -10.803946, ce loss: 0.012812 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.997869, training loss: 10.816758\n",
      "epoch 31, minibatch 183/183, validation loss 13.592033\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.92600298, -2.15515447, -2.80481601,  4.94152451,  0.56213021],\n",
      "       [-3.02130389,  4.87229633,  0.20042735, -3.45278573, -1.57714295],\n",
      "       [-1.22535074, -3.40218449,  3.07999802, -0.15112476,  1.5953356 ],\n",
      "       ..., \n",
      "       [-5.1504631 ,  1.2084018 ,  2.99941754, -1.75219941,  1.20923603],\n",
      "       [-0.91074765, -1.20242476, -1.78855824, -2.83406138,  2.32708597],\n",
      "       [ 1.99230027,  2.57991576,  2.62819386, -3.34774876, -4.07216787]], dtype=float32) \n",
      " decoder log variance: array([[-4.54606867, -5.08298397, -4.55969763, -4.04464674, -4.86383104],\n",
      "       [-3.61186814, -3.76341295, -4.97353029, -5.35759354, -3.66162825],\n",
      "       [-4.31072664, -4.99204206, -3.57748485, -4.57308292, -5.02023792],\n",
      "       ..., \n",
      "       [-2.28614855, -2.3238306 , -2.53956366, -2.69290257, -3.81678319],\n",
      "       [-1.19663322,  0.73403388, -1.67779267, -3.43229342,  1.77730978],\n",
      "       [-1.705616  , -2.30140185, -3.23704314, -4.25164127, -1.9142698 ]], dtype=float32) \n",
      "\n",
      "kl loss: -10.875067, ce loss: 0.015297 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.998397, training loss: 10.890364\n",
      "epoch 32, minibatch 183/183, validation loss 13.734234\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.04998112, -2.12432933, -2.77593923,  4.96130085,  0.61206609],\n",
      "       [-2.97511768,  4.93366957,  0.2258787 , -3.44953752, -1.48183608],\n",
      "       [-1.16028559, -3.3645227 ,  3.04372239, -0.12860247,  1.67777205],\n",
      "       ..., \n",
      "       [-5.07637024,  1.26697862,  2.98746514, -1.75123405,  1.22762108],\n",
      "       [-0.81200469, -1.17681527, -1.76275289, -2.84281087,  2.43974161],\n",
      "       [ 1.98774195,  2.70211053,  2.58593965, -3.36122155, -4.00565434]], dtype=float32) \n",
      " decoder log variance: array([[-4.49737501, -5.04638386, -4.48181963, -4.07516336, -4.54041243],\n",
      "       [-3.83937669, -3.73372364, -4.86105776, -5.27497292, -3.60772586],\n",
      "       [-4.33371782, -4.75422573, -3.54030395, -4.49700642, -4.71434736],\n",
      "       ..., \n",
      "       [-2.42790031, -2.04212809, -2.41948342, -2.58636618, -3.32365441],\n",
      "       [-1.35427856,  0.85869545, -1.75788033, -3.46252418,  1.85479188],\n",
      "       [-1.95177948, -2.22704101, -3.24224114, -4.32408524, -1.80470157]], dtype=float32) \n",
      "\n",
      "kl loss: -10.923193, ce loss: 0.009862 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.998415, training loss: 10.933055\n",
      "epoch 33, minibatch 183/183, validation loss 13.950136\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.05975628, -2.05609512, -2.8962357 ,  5.0051465 ,  0.59334791],\n",
      "       [-2.98023534,  4.94825745,  0.20077609, -3.43559766, -1.50293493],\n",
      "       [-1.14670074, -3.34666777,  3.01210332, -0.09217807,  1.66245711],\n",
      "       ..., \n",
      "       [-5.05820465,  1.21636236,  2.99112654, -1.71374094,  1.19342971],\n",
      "       [-0.75464314, -1.1897831 , -1.83389854, -2.80497718,  2.40214276],\n",
      "       [ 2.02387714,  2.6944859 ,  2.54751134, -3.35930371, -4.04156733]], dtype=float32) \n",
      " decoder log variance: array([[-4.64843178, -5.3532176 , -4.44272995, -3.84534454, -4.70405436],\n",
      "       [-3.84581757, -4.00077677, -4.59354973, -4.79946756, -3.62684131],\n",
      "       [-4.39534569, -5.11031675, -3.42011046, -4.2117095 , -4.80878496],\n",
      "       ..., \n",
      "       [-2.25458765, -1.9481715 , -1.9719646 , -2.14703274, -3.21659136],\n",
      "       [-1.30048954,  0.57251143, -1.54449272, -3.16059852,  1.87611437],\n",
      "       [-1.86024785, -2.37371445, -2.83949542, -3.80643129, -1.84483635]], dtype=float32) \n",
      "\n",
      "kl loss: -11.252321, ce loss: 0.010051 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.998379, training loss: 11.262373\n",
      "epoch 34, minibatch 183/183, validation loss 13.837801\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.09346581, -2.17866611, -2.84217572,  5.00125313,  0.42892191],\n",
      "       [-2.98260832,  4.88371086,  0.19878876, -3.4436357 , -1.61297417],\n",
      "       [-1.14411914, -3.41594553,  3.0403409 , -0.09500062,  1.53033924],\n",
      "       ..., \n",
      "       [-5.09795284,  1.17063129,  2.98295259, -1.70908368,  1.11968088],\n",
      "       [-0.69763684, -1.26226532, -1.7918644 , -2.80796671,  2.20099711],\n",
      "       [ 1.9673804 ,  2.64066887,  2.55536342, -3.33328915, -4.09017181]], dtype=float32) \n",
      " decoder log variance: array([[-4.56230545, -5.30332279, -4.7785306 , -4.04762125, -4.83795786],\n",
      "       [-3.99990296, -4.05866098, -5.08081102, -5.2569108 , -4.01433754],\n",
      "       [-4.25944805, -5.13260221, -3.69233084, -4.42651463, -5.01241064],\n",
      "       ..., \n",
      "       [-1.96381462, -2.24692988, -2.45185828, -2.54956865, -3.36878705],\n",
      "       [-1.32939303,  0.57819164, -1.81363559, -3.46918464,  1.56968534],\n",
      "       [-1.69712305, -2.30225635, -3.16433001, -4.13606644, -2.0211103 ]], dtype=float32) \n",
      "\n",
      "kl loss: -10.953055, ce loss: 0.010895 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.998761, training loss: 10.963951\n",
      "epoch 35, minibatch 183/183, validation loss 13.493428\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.03409672, -2.13594055, -2.77639031,  4.94930983,  0.55817878],\n",
      "       [-3.00047541,  4.89566517,  0.23601297, -3.45846462, -1.52350175],\n",
      "       [-1.1722703 , -3.38745856,  3.09461284, -0.12913953,  1.61906302],\n",
      "       ..., \n",
      "       [-5.0677824 ,  1.20455432,  3.02929449, -1.7289201 ,  1.17497838],\n",
      "       [-0.72760862, -1.24896884, -1.744663  , -2.85255122,  2.31774735],\n",
      "       [ 2.007478  ,  2.64666009,  2.60768914, -3.35955143, -4.03580093]], dtype=float32) \n",
      " decoder log variance: array([[-4.80893326, -5.58645535, -4.85617733, -4.24117708, -4.85895443],\n",
      "       [-4.06758499, -4.23399258, -5.10858059, -5.28562021, -3.99794054],\n",
      "       [-4.47395611, -5.24070263, -3.77317572, -4.60103989, -5.08132076],\n",
      "       ..., \n",
      "       [-2.18763518, -2.30321598, -2.5023818 , -2.62536502, -3.43572164],\n",
      "       [-1.28034174,  0.60131031, -1.77060008, -3.47569394,  1.75176883],\n",
      "       [-1.88564646, -2.53470278, -3.20510936, -4.23577547, -2.09978485]], dtype=float32) \n",
      "\n",
      "kl loss: -10.430510, ce loss: 0.009675 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.998944, training loss: 10.440185\n",
      "epoch 36, minibatch 183/183, validation loss 13.980388\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 4.00814342, -2.1461916 , -2.80504704,  4.96078444,  0.48721641],\n",
      "       [-2.98325133,  4.89977455,  0.2273646 , -3.45564723, -1.57478869],\n",
      "       [-1.16757011, -3.39791942,  3.0896709 , -0.10877507,  1.57200837],\n",
      "       ..., \n",
      "       [-5.06778097,  1.14000773,  3.02622843, -1.73178697,  1.19222939],\n",
      "       [-0.67008859, -1.22926748, -1.76844883, -2.82840776,  2.20128942],\n",
      "       [ 2.01137233,  2.56242871,  2.59739351, -3.36597872, -3.99904919]], dtype=float32) \n",
      " decoder log variance: array([[-4.91212749, -5.39997244, -4.84314728, -4.2883625 , -4.97705793],\n",
      "       [-4.35353661, -4.20469284, -5.12107563, -5.2860527 , -4.12949038],\n",
      "       [-4.54139233, -5.07979155, -3.73546982, -4.5919714 , -5.08136272],\n",
      "       ..., \n",
      "       [-2.34926915, -1.99518681, -2.36274171, -2.54767513, -3.50124884],\n",
      "       [-1.45634425,  0.66970664, -1.70936394, -3.45597696,  1.68002892],\n",
      "       [-2.12940717, -2.40230012, -3.19527316, -4.23171043, -2.24896288]], dtype=float32) \n",
      "\n",
      "kl loss: -10.489538, ce loss: 0.006744 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.998944, training loss: 10.496284\n",
      "epoch 37, minibatch 183/183, validation loss 13.794203\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99467087, -2.17482615, -2.86531949,  4.95995045,  0.52943945],\n",
      "       [-3.03199387,  4.88385057,  0.19570272, -3.45058751, -1.55216181],\n",
      "       [-1.20776379, -3.40991616,  3.05601931, -0.10401745,  1.59009993],\n",
      "       ..., \n",
      "       [-5.09783316,  1.17821956,  3.01925659, -1.71781194,  1.18118763],\n",
      "       [-0.7765128 , -1.24987328, -1.81184614, -2.84363389,  2.27410221],\n",
      "       [ 2.01395893,  2.58084726,  2.5590663 , -3.35718274, -4.03538561]], dtype=float32) \n",
      " decoder log variance: array([[-4.91799116, -5.73752069, -4.65175581, -4.55109596, -5.05833387],\n",
      "       [-4.25785208, -4.51835489, -4.86592293, -5.45100164, -4.28563452],\n",
      "       [-4.5688343 , -5.23382902, -3.56922412, -4.83252764, -5.27036285],\n",
      "       ..., \n",
      "       [-2.11598468, -2.12139297, -1.99509752, -2.67203331, -3.58859992],\n",
      "       [-1.34984052,  0.59007716, -1.7834537 , -3.72719288,  1.67879796],\n",
      "       [-2.13117361, -2.70317507, -3.03492975, -4.52788115, -2.43056512]], dtype=float32) \n",
      "\n",
      "kl loss: -10.350185, ce loss: 0.007871 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.999199, training loss: 10.358057\n",
      "epoch 38, minibatch 183/183, validation loss 13.962709\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99578977, -2.19135118, -2.78872228,  4.94247675,  0.52137065],\n",
      "       [-3.01101518,  4.87880993,  0.23513633, -3.44253445, -1.56404841],\n",
      "       [-1.16648257, -3.41277456,  3.10139251, -0.10483371,  1.5717932 ],\n",
      "       ..., \n",
      "       [-5.06634855,  1.15701056,  3.03143764, -1.72913599,  1.17243767],\n",
      "       [-0.73449457, -1.26173127, -1.75955021, -2.85782743,  2.25813794],\n",
      "       [ 2.0733161 ,  2.53770399,  2.59610486, -3.35526562, -4.06891775]], dtype=float32) \n",
      " decoder log variance: array([[-5.09468365, -5.72680283, -4.98057079, -4.58385563, -5.15082932],\n",
      "       [-4.40503263, -4.42889786, -5.14081049, -5.394063  , -4.21452665],\n",
      "       [-4.66048241, -5.35196638, -3.90366936, -4.83803844, -5.21486187],\n",
      "       ..., \n",
      "       [-2.15757608, -2.18846655, -2.4668324 , -2.63892078, -3.62883997],\n",
      "       [-1.4317311 ,  0.68203932, -1.91331625, -3.7179637 ,  1.7780472 ],\n",
      "       [-2.23109794, -2.63947558, -3.34716082, -4.52634287, -2.37396336]], dtype=float32) \n",
      "\n",
      "kl loss: -10.102558, ce loss: 0.006833 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.999454, training loss: 10.109392\n",
      "epoch 39, minibatch 183/183, validation loss 14.123239\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.98151636, -2.1880331 , -2.78712964,  4.90670872,  0.52950966],\n",
      "       [-3.02385283,  4.88185835,  0.22860484, -3.43970442, -1.56770492],\n",
      "       [-1.16608918, -3.41882324,  3.10070872, -0.11267748,  1.55427969],\n",
      "       ..., \n",
      "       [-5.07161522,  1.16509271,  3.02771235, -1.73860013,  1.15998578],\n",
      "       [-0.72976226, -1.25386167, -1.77027118, -2.88528299,  2.24480319],\n",
      "       [ 2.05331469,  2.53038049,  2.58737063, -3.36360884, -4.03568888]], dtype=float32) \n",
      " decoder log variance: array([[-5.13144064, -5.77393484, -5.01654959, -4.61627531, -5.22295427],\n",
      "       [-4.4829936 , -4.50669241, -5.16010332, -5.3156743 , -4.24320698],\n",
      "       [-4.71338463, -5.32874393, -3.89185286, -4.86159182, -5.1739974 ],\n",
      "       ..., \n",
      "       [-2.19722009, -2.15252662, -2.36809325, -2.50018311, -3.56359601],\n",
      "       [-1.42571855,  0.61112994, -1.91889417, -3.70100999,  1.75253689],\n",
      "       [-2.32720661, -2.72305155, -3.31516218, -4.50874376, -2.39915395]], dtype=float32) \n",
      "\n",
      "kl loss: -10.021429, ce loss: 0.005950 \n",
      "\n",
      "epoch training accuracy ec: 1.000000, dc: 0.999271, training loss: 10.027378\n",
      "epoch 40, minibatch 183/183, validation loss 14.281622\n",
      "encoder mean: array([[ 4.04119444, -2.12843251, -2.77285242,  4.78763962,  0.53275043],\n",
      "       [-3.09540081,  4.82564592,  0.16636227, -3.39685822, -1.3971765 ],\n",
      "       [-1.1195488 , -3.34888959,  3.05255055, -0.03649247,  1.57886231],\n",
      "       ..., \n",
      "       [-5.61994076,  1.72047782,  2.85092378, -2.12193513,  1.20171058],\n",
      "       [-1.23175061, -2.64971924, -1.57763505, -3.16362715,  4.27725458],\n",
      "       [ 2.40320706,  2.15034628,  2.31920648, -3.40669465, -3.79463673]], dtype=float32) \n",
      " encoder log variance: array([[ -7.54953766, -10.18026352,  -6.47065783,  -7.99101353,\n",
      "         -6.97187948],\n",
      "       [ -7.11678553,  -8.79536438,  -7.594594  ,  -7.39188099,\n",
      "         -7.04136658],\n",
      "       [ -8.45970726,  -8.29392338,  -7.0951848 ,  -7.60833073,\n",
      "         -6.54877996],\n",
      "       ..., \n",
      "       [ -6.90693998,  -7.85299635,  -7.09510279,  -7.06558561,\n",
      "         -6.61291695],\n",
      "       [ -7.85769892,  -9.082757  ,  -6.95870733,  -7.65521193,\n",
      "         -6.29850292],\n",
      "       [ -7.06723547,  -8.41772938,  -7.25212908,  -7.34684372,\n",
      "         -6.93388081]], dtype=float32) \n",
      " decoder mean: array([[ 3.99510217, -2.17880201, -2.80076194,  4.89725828,  0.53374898],\n",
      "       [-3.02255797,  4.88757896,  0.22584862, -3.44543076, -1.56632018],\n",
      "       [-1.15114462, -3.41282392,  3.09913683, -0.1159476 ,  1.55757701],\n",
      "       ..., \n",
      "       [-5.04781771,  1.16919494,  3.01437664, -1.75121534,  1.16419947],\n",
      "       [-0.70684487, -1.27194202, -1.7594682 , -2.90166903,  2.23750448],\n",
      "       [ 2.08146214,  2.53841281,  2.58556318, -3.37189913, -4.06480598]], dtype=float32) \n",
      " decoder log variance: array([[-5.18389988, -5.85215187, -5.11591387, -4.62473297, -5.35067606],\n",
      "       [-4.50221729, -4.53514767, -5.2433753 , -5.20203924, -4.28578091],\n",
      "       [-4.71868992, -5.43074656, -4.06232595, -4.9779253 , -5.27067804],\n",
      "       ..., \n",
      "       [-2.07066989, -2.09461236, -2.41715145, -2.52594519, -3.61929774],\n",
      "       [-1.3415345 ,  0.65958256, -1.89845669, -3.65218616,  1.74172449],\n",
      "       [-2.33953929, -2.78607845, -3.36732864, -4.52771902, -2.51940536]], dtype=float32) \n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# TRAIN MODEL #\n",
    "###############\n",
    "'''\n",
    "Define :\n",
    "    xx_loss : Cost function value\n",
    "    xx_score : Classification accuracy rate\n",
    "'''        \n",
    "    \n",
    "print('... training')\n",
    "    \n",
    "# early-stopping parameters\n",
    "patience = 10000  # look as this many examples regardless\n",
    "patience_increase = 2  # wait this much longer when a new best is\n",
    "                           # found\n",
    "improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                   # considered significant\n",
    "validation_frequency = min(n_train_batches, patience // 2)\n",
    "                                  # go through this many\n",
    "                                  # minibatche before checking the network\n",
    "                                  # on the validation set; in this case we\n",
    "                                  # check every epoch\n",
    "    \n",
    "#validation_frequency = n_train_batches\n",
    "    \n",
    "best_iter = 0\n",
    "best_train_loss = np.inf\n",
    "best_validation_loss = np.inf  \n",
    "test_loss = np.inf\n",
    "train_score = 0.\n",
    "validation_score = 0.\n",
    "test_score = 0.    \n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "epoch = 0\n",
    "done_looping = False\n",
    "\n",
    "\n",
    "while (epoch < n_epochs) and (not done_looping):\n",
    "    epoch = epoch + 1\n",
    "    train_acc1=[]\n",
    "    train_acc2=[]\n",
    "    for minibatch_index in range(n_train_batches):\n",
    "\n",
    "        #[minibatch_avg_cost, pred1, lab, pred2] \\\n",
    "        #= train_model(minibatch_index)\n",
    "        [minibatch_avg_cost, pred1, lab, pred2, ec_mu, ec_log_sigma, dc_mu, dc_log_sigma, kl, ce] \\\n",
    "        = train_model(minibatch_index)\n",
    "        #print(minibatch_index)\n",
    "                        \n",
    "        # iteration number\n",
    "        iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "        #print(pred1)\n",
    "        #print(classifier_kl.phi_sigma.OL.W.get_value())\n",
    "        train_acc1.append(get_acc(pred1, np.nonzero(lab)[1]))\n",
    "        train_acc2.append(get_acc(pred2, np.nonzero(lab)[1]))\n",
    "            \n",
    "        if (iter + 1) % validation_frequency == 0:\n",
    "            # compute loss on validation set\n",
    "            validation_losses = [validate_model(i) for i in range(n_valid_batches)] \n",
    "            this_validation_loss = np.mean(validation_losses)\n",
    "                \n",
    "            #print('CE loss: %f' % (np.mean(KL_loss)))\n",
    "            #print('encoder mu: %f, sigma: %f' % (ec_m, ec_s))\n",
    "            #print('decoder mu: %f, sigma: %f' % (dc_m, dc_s))\n",
    "            #print(ec_m)\n",
    "            #print(dc_m)\n",
    "            #print(ec_s)\n",
    "            #print(dc_s)\n",
    "            \n",
    "            #print('epoch training accuracy ec: %f, dc: %f, training loss: %f \\n trainig kl: %f, ce: %f' \\\n",
    "            #    % (np.mean(np.array(train_acc1)), np.mean(np.array(train_acc2)),np.mean(minibatch_avg_cost), \\\n",
    "            #      np.mean(kl), np.mean(ce)))\n",
    "            print('encoder mean: %r \\n encoder log variance: %r \\n decoder mean: %r \\n decoder log variance: %r \\n' \\\n",
    "                  % (ec_mu, ec_log_sigma, dc_mu, dc_log_sigma))\n",
    "            print('kl loss: %f, ce loss: %f \\n' \\\n",
    "                % (kl.mean() ,ce.mean()))\n",
    "            print('epoch training accuracy ec: %f, dc: %f, training loss: %f' \\\n",
    "                % (np.mean(np.array(train_acc1)), np.mean(np.array(train_acc2)),np.mean(minibatch_avg_cost)))\n",
    "            print(\n",
    "                'epoch %i, minibatch %i/%i, validation loss %f' %\n",
    "                (\n",
    "                    epoch,\n",
    "                    minibatch_index + 1,\n",
    "                    n_train_batches,\n",
    "                    this_validation_loss\n",
    "                )\n",
    "            )\n",
    "            test_acc=[]\n",
    "                for minibatch_index in range(n_test_batches):\n",
    "                    [pred_test, lab_test]= test_model(minibatch_index)\n",
    "                    #print(pred)\n",
    "                    #print(np.nonzero(lab)[1])\n",
    "                    # iteration number\n",
    "                    iter = minibatch_index\n",
    "                    test_acc.append(get_acc(pred_test, np.nonzero(lab_test)[1]))\n",
    "    \n",
    "            print('test accuracy: %f' % (np.mean(test_acc)))\n",
    "\n",
    "            # if we got the best validation score until now\n",
    "            if this_validation_loss < best_validation_loss:\n",
    "                #improve patience if loss improvement is good enough\n",
    "                if (\n",
    "                    this_validation_loss < best_validation_loss *\n",
    "                    improvement_threshold\n",
    "                ):\n",
    "                    patience = max(patience, iter * patience_increase)\n",
    "\n",
    "                best_validation_loss = this_validation_loss   \n",
    "                best_iter = iter\n",
    "                '''\n",
    "                # get training accuracy\n",
    "                print('best training accuracy: %f' % (np.mean(np.array(train_acc))))\n",
    "                # test it on the test set\n",
    "                #test_losses = [test_model(i) for i in range(n_test_batches)]\n",
    "                #test_score = np.mean(test_losses)\n",
    "\n",
    "                print(('epoch %i, minibatch %i/%i, best train accuracy: %f') % \\\n",
    "                        (epoch, minibatch_index + 1, n_train_batches, \\\n",
    "                        np.mean(np.array(train_acc))))\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                \n",
    "        #if patience <= iter:\n",
    "        #    done_looping = True\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
