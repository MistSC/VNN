{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict\n",
    "from six.moves import cPickle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import nnet as nn\n",
    "import criteria as er\n",
    "import util\n",
    "import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of minibatch at one epoch: train  137, validation 12, test 25\n",
      "55000\n",
      "55000\n",
      "784\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "'''Load Data'''\n",
    "train_file = 'train_1ok.npy'\n",
    "valid_file = 'valid_1ok.npy'\n",
    "test_file = 'test_1ok.npy'\n",
    "    \n",
    "train=np.load(train_file)\n",
    "valid=np.load(valid_file)\n",
    "test=np.load(test_file)\n",
    "    \n",
    "#train_list=np.load('train.npy')[1]\n",
    "    \n",
    "\n",
    "train_feat, train_label = util.shared_dataset(train)\n",
    "valid_feat, valid_label = util.shared_dataset(valid)\n",
    "test_feat, test_label = util.shared_dataset(test)\n",
    "    \n",
    "  \n",
    "'''Coefficient Initial'''        \n",
    "batch_size = 400\n",
    "n_epochs = 100\n",
    "learning_rate = 0.05\n",
    "    \n",
    "n_train_batches = train_feat.get_value(borrow=True).shape[0] // batch_size\n",
    "n_valid_batches = valid_feat.get_value(borrow=True).shape[0] // batch_size\n",
    "n_test_batches = test_feat.get_value(borrow=True).shape[0] // batch_size\n",
    "print('number of minibatch at one epoch: train  %i, validation %i, test %i' %\n",
    "    (n_train_batches, n_valid_batches, n_test_batches))\n",
    "    \n",
    "z_dim = 5 #dimension of latent variable \n",
    "x_dim = train_feat.get_value(borrow=True).shape[1]\n",
    "y_dim = train_label.get_value(borrow=True).shape[1]\n",
    "activation = None\n",
    "    \n",
    "print(train_feat.get_value(borrow=True).shape[0])\n",
    "print(train_label.get_value(borrow=True).shape[0])\n",
    "print(train_feat.get_value(borrow=True).shape[1])\n",
    "print(train_label.get_value(borrow=True).shape[1])\n",
    "\n",
    "phi_1_struct=nn.NN_struct()\n",
    "phi_1_struct.layer_dim = [x_dim, z_dim]\n",
    "phi_1_struct.activation = [activation]\n",
    "    \n",
    "theta_1_struct=nn.NN_struct()\n",
    "theta_1_struct.layer_dim = [z_dim, x_dim]\n",
    "theta_1_struct.activation = [activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "... prepare training model\n",
      "... prepare validate model\n",
      "... prepare test model\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# BUILD ACTUAL MODEL #\n",
    "######################\n",
    "print('... building the model')\n",
    "    \n",
    "    \n",
    "# allocate symbolic variables for the data\n",
    "#index_source = T.lscalar()  # index to a [mini]batch\n",
    "#index_target = T.lscalar()  # index to a [mini]batch\n",
    "index = T.lscalar()  # index to a [mini]batch\n",
    "x = T.matrix('x')  # the data is presented as rasterized images\n",
    "#y = T.matrix('y')  # the labels are presented as signal vector     \n",
    "    \n",
    "rng = np.random.RandomState(1234)\n",
    "        \n",
    "# construct the DAVAE class\n",
    "   \n",
    "classifier = VAE.Unsupervised_VAE(\n",
    "    rng=rng,\n",
    "    input_x = x,\n",
    "    label_y = x,\n",
    "    batch_size = batch_size,\n",
    "    phi_1_struct = phi_1_struct,\n",
    "    theta_1_struct = theta_1_struct,\n",
    "    in_dim = x_dim,\n",
    "    out_dim = x_dim\n",
    "    )\n",
    "    \n",
    "    \n",
    "cost = (classifier.cost)\n",
    "        \n",
    "gparams = [T.grad(cost, param) for param in classifier.params]\n",
    "                   \n",
    "updates = [\n",
    "    (param, param - learning_rate * gparam)\n",
    "    for param, gparam in zip(classifier.params, gparams)\n",
    "]\n",
    "    \n",
    "print('... prepare training model')\n",
    "train_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=[classifier.cost, classifier.predictor, classifier.label_y],\n",
    "    updates=updates,\n",
    "    givens={\n",
    "        x: train_feat[index * batch_size : (index + 1) * batch_size, :]\n",
    "    }       \n",
    ")   \n",
    "    \n",
    "    \n",
    "print('... prepare validate model')\n",
    "validate_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=classifier.cost,\n",
    "    givens={\n",
    "        x: valid_feat[index * batch_size : (index + 1) * batch_size, :]\n",
    "    }        \n",
    ")                \n",
    "    \n",
    "    \n",
    "print('... prepare test model')\n",
    "test_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=classifier.predictor,\n",
    "    givens={\n",
    "        x: test_feat[index * batch_size : (index + 1) * batch_size, :]\n",
    "    }        \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training\n",
      "epoch 1, minibatch 0/137, training loss 0.723390\n",
      "epoch 1, minibatch 40/137, training loss 0.696983\n",
      "epoch 1, minibatch 80/137, training loss 0.682252\n",
      "epoch 1, minibatch 120/137, training loss 0.666721\n",
      "epoch 1, minibatch 137/137, validation loss 0.659833\n",
      "epoch 2, minibatch 23/137, training loss 0.646860\n",
      "epoch 2, minibatch 63/137, training loss 0.614995\n",
      "epoch 2, minibatch 103/137, training loss 0.572044\n",
      "epoch 2, minibatch 137/137, validation loss 0.525635\n",
      "epoch 3, minibatch 6/137, training loss 0.515090\n",
      "epoch 3, minibatch 46/137, training loss 0.463929\n",
      "epoch 3, minibatch 86/137, training loss 0.422043\n",
      "epoch 3, minibatch 126/137, training loss 0.383079\n",
      "epoch 3, minibatch 137/137, validation loss 0.376055\n",
      "epoch 4, minibatch 29/137, training loss 0.348769\n",
      "epoch 4, minibatch 69/137, training loss 0.333053\n",
      "epoch 4, minibatch 109/137, training loss 0.311774\n",
      "epoch 4, minibatch 137/137, validation loss 0.314068\n",
      "epoch 5, minibatch 12/137, training loss 0.318572\n",
      "epoch 5, minibatch 52/137, training loss 0.302279\n",
      "epoch 5, minibatch 92/137, training loss 0.294604\n",
      "epoch 5, minibatch 132/137, training loss 0.288576\n",
      "epoch 5, minibatch 137/137, validation loss 0.292789\n",
      "epoch 6, minibatch 35/137, training loss 0.313206\n",
      "epoch 6, minibatch 75/137, training loss 0.288156\n",
      "epoch 6, minibatch 115/137, training loss 0.281242\n",
      "epoch 6, minibatch 137/137, validation loss 0.284227\n",
      "epoch 7, minibatch 18/137, training loss 0.274403\n",
      "epoch 7, minibatch 58/137, training loss 0.284390\n",
      "epoch 7, minibatch 98/137, training loss 0.279483\n",
      "epoch 7, minibatch 137/137, validation loss 0.279861\n",
      "epoch 8, minibatch 1/137, training loss 0.278920\n",
      "epoch 8, minibatch 41/137, training loss 0.271305\n",
      "epoch 8, minibatch 81/137, training loss 0.282364\n",
      "epoch 8, minibatch 121/137, training loss 0.285756\n",
      "epoch 8, minibatch 137/137, validation loss 0.277099\n",
      "epoch 9, minibatch 24/137, training loss 0.279537\n",
      "epoch 9, minibatch 64/137, training loss 0.269036\n",
      "epoch 9, minibatch 104/137, training loss 0.272745\n",
      "epoch 9, minibatch 137/137, validation loss 0.275055\n",
      "epoch 10, minibatch 7/137, training loss 0.268661\n",
      "epoch 10, minibatch 47/137, training loss 0.265707\n",
      "epoch 10, minibatch 87/137, training loss 0.270454\n",
      "epoch 10, minibatch 127/137, training loss 0.262085\n",
      "epoch 10, minibatch 137/137, validation loss 0.273543\n",
      "epoch 11, minibatch 30/137, training loss 0.278894\n",
      "epoch 11, minibatch 70/137, training loss 0.283100\n",
      "epoch 11, minibatch 110/137, training loss 0.273746\n",
      "epoch 11, minibatch 137/137, validation loss 0.272193\n",
      "epoch 12, minibatch 13/137, training loss 0.278718\n",
      "epoch 12, minibatch 53/137, training loss 0.280669\n",
      "epoch 12, minibatch 93/137, training loss 0.272045\n",
      "epoch 12, minibatch 133/137, training loss 0.265118\n",
      "epoch 12, minibatch 137/137, validation loss 0.270909\n",
      "epoch 13, minibatch 36/137, training loss 0.278185\n",
      "epoch 13, minibatch 76/137, training loss 0.265803\n",
      "epoch 13, minibatch 116/137, training loss 0.271353\n",
      "epoch 13, minibatch 137/137, validation loss 0.269804\n",
      "epoch 14, minibatch 19/137, training loss 0.275823\n",
      "epoch 14, minibatch 59/137, training loss 0.269720\n",
      "epoch 14, minibatch 99/137, training loss 0.267168\n",
      "epoch 14, minibatch 137/137, validation loss 0.268693\n",
      "epoch 15, minibatch 2/137, training loss 0.266344\n",
      "epoch 15, minibatch 42/137, training loss 0.268827\n",
      "epoch 15, minibatch 82/137, training loss 0.268306\n",
      "epoch 15, minibatch 122/137, training loss 0.268297\n",
      "epoch 15, minibatch 137/137, validation loss 0.267566\n",
      "epoch 16, minibatch 25/137, training loss 0.282968\n",
      "epoch 16, minibatch 65/137, training loss 0.258458\n",
      "epoch 16, minibatch 105/137, training loss 0.268306\n",
      "epoch 16, minibatch 137/137, validation loss 0.266440\n",
      "epoch 17, minibatch 8/137, training loss 0.257569\n",
      "epoch 17, minibatch 48/137, training loss 0.280548\n",
      "epoch 17, minibatch 88/137, training loss 0.267000\n",
      "epoch 17, minibatch 128/137, training loss 0.274383\n",
      "epoch 17, minibatch 137/137, validation loss 0.265194\n",
      "epoch 18, minibatch 31/137, training loss 0.275565\n",
      "epoch 18, minibatch 71/137, training loss 0.271720\n",
      "epoch 18, minibatch 111/137, training loss 0.261009\n",
      "epoch 18, minibatch 137/137, validation loss 0.263930\n",
      "epoch 19, minibatch 14/137, training loss 0.264820\n",
      "epoch 19, minibatch 54/137, training loss 0.266630\n",
      "epoch 19, minibatch 94/137, training loss 0.268238\n",
      "epoch 19, minibatch 134/137, training loss 0.259531\n",
      "epoch 19, minibatch 137/137, validation loss 0.262560\n",
      "epoch 20, minibatch 37/137, training loss 0.260099\n",
      "epoch 20, minibatch 77/137, training loss 0.252406\n",
      "epoch 20, minibatch 117/137, training loss 0.260936\n",
      "epoch 20, minibatch 137/137, validation loss 0.261142\n",
      "epoch 21, minibatch 20/137, training loss 0.261642\n",
      "epoch 21, minibatch 60/137, training loss 0.249789\n",
      "epoch 21, minibatch 100/137, training loss 0.258457\n",
      "epoch 21, minibatch 137/137, validation loss 0.259676\n",
      "epoch 22, minibatch 3/137, training loss 0.266700\n",
      "epoch 22, minibatch 43/137, training loss 0.263153\n",
      "epoch 22, minibatch 83/137, training loss 0.258998\n",
      "epoch 22, minibatch 123/137, training loss 0.264327\n",
      "epoch 22, minibatch 137/137, validation loss 0.258019\n",
      "epoch 23, minibatch 26/137, training loss 0.255703\n",
      "epoch 23, minibatch 66/137, training loss 0.255575\n",
      "epoch 23, minibatch 106/137, training loss 0.266881\n",
      "epoch 23, minibatch 137/137, validation loss 0.256405\n",
      "epoch 24, minibatch 9/137, training loss 0.258884\n",
      "epoch 24, minibatch 49/137, training loss 0.275583\n",
      "epoch 24, minibatch 89/137, training loss 0.256777\n",
      "epoch 24, minibatch 129/137, training loss 0.252079\n",
      "epoch 24, minibatch 137/137, validation loss 0.254788\n",
      "epoch 25, minibatch 32/137, training loss 0.267299\n",
      "epoch 25, minibatch 72/137, training loss 0.262483\n",
      "epoch 25, minibatch 112/137, training loss 0.251488\n",
      "epoch 25, minibatch 137/137, validation loss 0.252997\n",
      "epoch 26, minibatch 15/137, training loss 0.260373\n",
      "epoch 26, minibatch 55/137, training loss 0.262245\n",
      "epoch 26, minibatch 95/137, training loss 0.250991\n",
      "epoch 26, minibatch 135/137, training loss 0.247839\n",
      "epoch 26, minibatch 137/137, validation loss 0.251413\n",
      "epoch 27, minibatch 38/137, training loss 0.245305\n",
      "epoch 27, minibatch 78/137, training loss 0.246644\n",
      "epoch 27, minibatch 118/137, training loss 0.252736\n",
      "epoch 27, minibatch 137/137, validation loss 0.249634\n",
      "epoch 28, minibatch 21/137, training loss 0.259106\n",
      "epoch 28, minibatch 61/137, training loss 0.254153\n",
      "epoch 28, minibatch 101/137, training loss 0.255993\n",
      "epoch 28, minibatch 137/137, validation loss 0.247989\n",
      "epoch 29, minibatch 4/137, training loss 0.243608\n",
      "epoch 29, minibatch 44/137, training loss 0.239943\n",
      "epoch 29, minibatch 84/137, training loss 0.235084\n",
      "epoch 29, minibatch 124/137, training loss 0.245868\n",
      "epoch 29, minibatch 137/137, validation loss 0.246334\n",
      "epoch 30, minibatch 27/137, training loss 0.241870\n",
      "epoch 30, minibatch 67/137, training loss 0.244604\n",
      "epoch 30, minibatch 107/137, training loss 0.235218\n",
      "epoch 30, minibatch 137/137, validation loss 0.244665\n",
      "epoch 31, minibatch 10/137, training loss 0.240334\n",
      "epoch 31, minibatch 50/137, training loss 0.252626\n",
      "epoch 31, minibatch 90/137, training loss 0.256636\n",
      "epoch 31, minibatch 130/137, training loss 0.236211\n",
      "epoch 31, minibatch 137/137, validation loss 0.243086\n",
      "epoch 32, minibatch 33/137, training loss 0.253815\n",
      "epoch 32, minibatch 73/137, training loss 0.243395\n",
      "epoch 32, minibatch 113/137, training loss 0.245279\n",
      "epoch 32, minibatch 137/137, validation loss 0.241542\n",
      "epoch 33, minibatch 16/137, training loss 0.232237\n",
      "epoch 33, minibatch 56/137, training loss 0.249291\n",
      "epoch 33, minibatch 96/137, training loss 0.242944\n",
      "epoch 33, minibatch 136/137, training loss 0.234895\n",
      "epoch 33, minibatch 137/137, validation loss 0.239962\n",
      "epoch 34, minibatch 39/137, training loss 0.239196\n",
      "epoch 34, minibatch 79/137, training loss 0.241135\n",
      "epoch 34, minibatch 119/137, training loss 0.247401\n",
      "epoch 34, minibatch 137/137, validation loss 0.238519\n",
      "epoch 35, minibatch 22/137, training loss 0.230993\n",
      "epoch 35, minibatch 62/137, training loss 0.228431\n",
      "epoch 35, minibatch 102/137, training loss 0.235255\n",
      "epoch 35, minibatch 137/137, validation loss 0.237003\n",
      "epoch 36, minibatch 5/137, training loss 0.235260\n",
      "epoch 36, minibatch 45/137, training loss 0.223144\n",
      "epoch 36, minibatch 85/137, training loss 0.231167\n",
      "epoch 36, minibatch 125/137, training loss 0.228371\n",
      "epoch 36, minibatch 137/137, validation loss 0.235626\n",
      "epoch 37, minibatch 28/137, training loss 0.226216\n",
      "epoch 37, minibatch 68/137, training loss 0.243190\n",
      "epoch 37, minibatch 108/137, training loss 0.233152\n",
      "epoch 37, minibatch 137/137, validation loss 0.234226\n",
      "epoch 38, minibatch 11/137, training loss 0.245837\n",
      "epoch 38, minibatch 51/137, training loss 0.227624\n",
      "epoch 38, minibatch 91/137, training loss 0.243503\n",
      "epoch 38, minibatch 131/137, training loss 0.226224\n",
      "epoch 38, minibatch 137/137, validation loss 0.232898\n",
      "epoch 39, minibatch 34/137, training loss 0.235470\n",
      "epoch 39, minibatch 74/137, training loss 0.223686\n",
      "epoch 39, minibatch 114/137, training loss 0.231057\n",
      "epoch 39, minibatch 137/137, validation loss 0.231663\n",
      "epoch 40, minibatch 17/137, training loss 0.227238\n",
      "epoch 40, minibatch 57/137, training loss 0.245533\n",
      "epoch 40, minibatch 97/137, training loss 0.226457\n",
      "epoch 40, minibatch 137/137, validation loss 0.230433\n",
      "epoch 41, minibatch 0/137, training loss 0.223714\n",
      "epoch 41, minibatch 40/137, training loss 0.223535\n",
      "epoch 41, minibatch 80/137, training loss 0.232791\n",
      "epoch 41, minibatch 120/137, training loss 0.239086\n",
      "epoch 41, minibatch 137/137, validation loss 0.229277\n",
      "epoch 42, minibatch 23/137, training loss 0.232827\n",
      "epoch 42, minibatch 63/137, training loss 0.234474\n",
      "epoch 42, minibatch 103/137, training loss 0.243263\n",
      "epoch 42, minibatch 137/137, validation loss 0.228153\n",
      "epoch 43, minibatch 6/137, training loss 0.231347\n",
      "epoch 43, minibatch 46/137, training loss 0.226728\n",
      "epoch 43, minibatch 86/137, training loss 0.233139\n",
      "epoch 43, minibatch 126/137, training loss 0.226654\n",
      "epoch 43, minibatch 137/137, validation loss 0.227094\n",
      "epoch 44, minibatch 29/137, training loss 0.217029\n",
      "epoch 44, minibatch 69/137, training loss 0.224345\n",
      "epoch 44, minibatch 109/137, training loss 0.218152\n",
      "epoch 44, minibatch 137/137, validation loss 0.226120\n",
      "epoch 45, minibatch 12/137, training loss 0.232712\n",
      "epoch 45, minibatch 52/137, training loss 0.224813\n",
      "epoch 45, minibatch 92/137, training loss 0.224079\n",
      "epoch 45, minibatch 132/137, training loss 0.223031\n",
      "epoch 45, minibatch 137/137, validation loss 0.225178\n",
      "epoch 46, minibatch 35/137, training loss 0.248816\n",
      "epoch 46, minibatch 75/137, training loss 0.227789\n",
      "epoch 46, minibatch 115/137, training loss 0.224602\n",
      "epoch 46, minibatch 137/137, validation loss 0.224295\n",
      "epoch 47, minibatch 18/137, training loss 0.217464\n",
      "epoch 47, minibatch 58/137, training loss 0.227442\n",
      "epoch 47, minibatch 98/137, training loss 0.225359\n",
      "epoch 47, minibatch 137/137, validation loss 0.223443\n",
      "epoch 48, minibatch 1/137, training loss 0.224126\n",
      "epoch 48, minibatch 41/137, training loss 0.218269\n",
      "epoch 48, minibatch 81/137, training loss 0.228755\n",
      "epoch 48, minibatch 121/137, training loss 0.229281\n",
      "epoch 48, minibatch 137/137, validation loss 0.222644\n",
      "epoch 49, minibatch 24/137, training loss 0.227367\n",
      "epoch 49, minibatch 64/137, training loss 0.215404\n",
      "epoch 49, minibatch 104/137, training loss 0.220030\n",
      "epoch 49, minibatch 137/137, validation loss 0.221886\n",
      "epoch 50, minibatch 7/137, training loss 0.217538\n",
      "epoch 50, minibatch 47/137, training loss 0.219034\n",
      "epoch 50, minibatch 87/137, training loss 0.222566\n",
      "epoch 50, minibatch 127/137, training loss 0.212651\n",
      "epoch 50, minibatch 137/137, validation loss 0.221182\n",
      "epoch 51, minibatch 30/137, training loss 0.228356\n",
      "epoch 51, minibatch 70/137, training loss 0.223843\n",
      "epoch 51, minibatch 110/137, training loss 0.229947\n",
      "epoch 51, minibatch 137/137, validation loss 0.220458\n",
      "epoch 52, minibatch 13/137, training loss 0.224646\n",
      "epoch 52, minibatch 53/137, training loss 0.226180\n",
      "epoch 52, minibatch 93/137, training loss 0.226072\n",
      "epoch 52, minibatch 133/137, training loss 0.213875\n",
      "epoch 52, minibatch 137/137, validation loss 0.219842\n",
      "epoch 53, minibatch 36/137, training loss 0.231252\n",
      "epoch 53, minibatch 76/137, training loss 0.218788\n",
      "epoch 53, minibatch 116/137, training loss 0.221269\n",
      "epoch 53, minibatch 137/137, validation loss 0.219259\n",
      "epoch 54, minibatch 19/137, training loss 0.223662\n",
      "epoch 54, minibatch 59/137, training loss 0.220690\n",
      "epoch 54, minibatch 99/137, training loss 0.220727\n",
      "epoch 54, minibatch 137/137, validation loss 0.218631\n",
      "epoch 55, minibatch 2/137, training loss 0.218664\n",
      "epoch 55, minibatch 42/137, training loss 0.223199\n",
      "epoch 55, minibatch 82/137, training loss 0.218261\n",
      "epoch 55, minibatch 122/137, training loss 0.220668\n",
      "epoch 55, minibatch 137/137, validation loss 0.218108\n",
      "epoch 56, minibatch 25/137, training loss 0.229918\n",
      "epoch 56, minibatch 65/137, training loss 0.209445\n",
      "epoch 56, minibatch 105/137, training loss 0.219817\n",
      "epoch 56, minibatch 137/137, validation loss 0.217592\n",
      "epoch 57, minibatch 8/137, training loss 0.207555\n",
      "epoch 57, minibatch 48/137, training loss 0.228139\n",
      "epoch 57, minibatch 88/137, training loss 0.219505\n",
      "epoch 57, minibatch 128/137, training loss 0.224772\n",
      "epoch 57, minibatch 137/137, validation loss 0.217079\n",
      "epoch 58, minibatch 31/137, training loss 0.228933\n",
      "epoch 58, minibatch 71/137, training loss 0.223211\n",
      "epoch 58, minibatch 111/137, training loss 0.214507\n",
      "epoch 58, minibatch 137/137, validation loss 0.216593\n",
      "epoch 59, minibatch 14/137, training loss 0.218253\n",
      "epoch 59, minibatch 54/137, training loss 0.214125\n",
      "epoch 59, minibatch 94/137, training loss 0.223283\n",
      "epoch 59, minibatch 134/137, training loss 0.217126\n",
      "epoch 59, minibatch 137/137, validation loss 0.216151\n",
      "epoch 60, minibatch 37/137, training loss 0.215519\n",
      "epoch 60, minibatch 77/137, training loss 0.208948\n",
      "epoch 60, minibatch 117/137, training loss 0.213270\n",
      "epoch 60, minibatch 137/137, validation loss 0.215699\n",
      "epoch 61, minibatch 20/137, training loss 0.216405\n",
      "epoch 61, minibatch 60/137, training loss 0.206032\n",
      "epoch 61, minibatch 100/137, training loss 0.214831\n",
      "epoch 61, minibatch 137/137, validation loss 0.215284\n",
      "epoch 62, minibatch 3/137, training loss 0.224182\n",
      "epoch 62, minibatch 43/137, training loss 0.225145\n",
      "epoch 62, minibatch 83/137, training loss 0.218925\n",
      "epoch 62, minibatch 123/137, training loss 0.223636\n",
      "epoch 62, minibatch 137/137, validation loss 0.214881\n",
      "epoch 63, minibatch 26/137, training loss 0.210857\n",
      "epoch 63, minibatch 66/137, training loss 0.215053\n",
      "epoch 63, minibatch 106/137, training loss 0.222300\n",
      "epoch 63, minibatch 137/137, validation loss 0.214515\n",
      "epoch 64, minibatch 9/137, training loss 0.219082\n",
      "epoch 64, minibatch 49/137, training loss 0.225754\n",
      "epoch 64, minibatch 89/137, training loss 0.216517\n",
      "epoch 64, minibatch 129/137, training loss 0.213097\n",
      "epoch 64, minibatch 137/137, validation loss 0.214091\n",
      "epoch 65, minibatch 32/137, training loss 0.226506\n",
      "epoch 65, minibatch 72/137, training loss 0.226468\n",
      "epoch 65, minibatch 112/137, training loss 0.214175\n",
      "epoch 65, minibatch 137/137, validation loss 0.213726\n",
      "epoch 66, minibatch 15/137, training loss 0.216544\n",
      "epoch 66, minibatch 55/137, training loss 0.224254\n",
      "epoch 66, minibatch 95/137, training loss 0.213375\n",
      "epoch 66, minibatch 135/137, training loss 0.212615\n",
      "epoch 66, minibatch 137/137, validation loss 0.213400\n",
      "epoch 67, minibatch 38/137, training loss 0.208934\n",
      "epoch 67, minibatch 78/137, training loss 0.211560\n",
      "epoch 67, minibatch 118/137, training loss 0.217162\n",
      "epoch 67, minibatch 137/137, validation loss 0.213096\n",
      "epoch 68, minibatch 21/137, training loss 0.220350\n",
      "epoch 68, minibatch 61/137, training loss 0.221588\n",
      "epoch 68, minibatch 101/137, training loss 0.219092\n",
      "epoch 68, minibatch 137/137, validation loss 0.212747\n",
      "epoch 69, minibatch 4/137, training loss 0.206615\n",
      "epoch 69, minibatch 44/137, training loss 0.208282\n",
      "epoch 69, minibatch 84/137, training loss 0.200815\n",
      "epoch 69, minibatch 124/137, training loss 0.214472\n",
      "epoch 69, minibatch 137/137, validation loss 0.212462\n",
      "epoch 70, minibatch 27/137, training loss 0.206315\n",
      "epoch 70, minibatch 67/137, training loss 0.212523\n",
      "epoch 70, minibatch 107/137, training loss 0.201593\n",
      "epoch 70, minibatch 137/137, validation loss 0.212162\n",
      "epoch 71, minibatch 10/137, training loss 0.208223\n",
      "epoch 71, minibatch 50/137, training loss 0.218036\n",
      "epoch 71, minibatch 90/137, training loss 0.221466\n",
      "epoch 71, minibatch 130/137, training loss 0.205723\n",
      "epoch 71, minibatch 137/137, validation loss 0.211827\n",
      "epoch 72, minibatch 33/137, training loss 0.220028\n",
      "epoch 72, minibatch 73/137, training loss 0.211372\n",
      "epoch 72, minibatch 113/137, training loss 0.214290\n",
      "epoch 72, minibatch 137/137, validation loss 0.211538\n",
      "epoch 73, minibatch 16/137, training loss 0.203234\n",
      "epoch 73, minibatch 56/137, training loss 0.219398\n",
      "epoch 73, minibatch 96/137, training loss 0.213003\n",
      "epoch 73, minibatch 136/137, training loss 0.205290\n",
      "epoch 73, minibatch 137/137, validation loss 0.211267\n",
      "epoch 74, minibatch 39/137, training loss 0.213538\n",
      "epoch 74, minibatch 79/137, training loss 0.215573\n",
      "epoch 74, minibatch 119/137, training loss 0.218478\n",
      "epoch 74, minibatch 137/137, validation loss 0.211016\n",
      "epoch 75, minibatch 22/137, training loss 0.204073\n",
      "epoch 75, minibatch 62/137, training loss 0.203558\n",
      "epoch 75, minibatch 102/137, training loss 0.208474\n",
      "epoch 75, minibatch 137/137, validation loss 0.210720\n",
      "epoch 76, minibatch 5/137, training loss 0.209451\n",
      "epoch 76, minibatch 45/137, training loss 0.198356\n",
      "epoch 76, minibatch 85/137, training loss 0.206586\n",
      "epoch 76, minibatch 125/137, training loss 0.205445\n",
      "epoch 76, minibatch 137/137, validation loss 0.210496\n",
      "epoch 77, minibatch 28/137, training loss 0.200570\n",
      "epoch 77, minibatch 68/137, training loss 0.219228\n",
      "epoch 77, minibatch 108/137, training loss 0.208367\n",
      "epoch 77, minibatch 137/137, validation loss 0.210258\n",
      "epoch 78, minibatch 11/137, training loss 0.220384\n",
      "epoch 78, minibatch 51/137, training loss 0.203625\n",
      "epoch 78, minibatch 91/137, training loss 0.220009\n",
      "epoch 78, minibatch 131/137, training loss 0.203904\n",
      "epoch 78, minibatch 137/137, validation loss 0.210005\n",
      "epoch 79, minibatch 34/137, training loss 0.212955\n",
      "epoch 79, minibatch 74/137, training loss 0.202745\n",
      "epoch 79, minibatch 114/137, training loss 0.210680\n",
      "epoch 79, minibatch 137/137, validation loss 0.209765\n",
      "epoch 80, minibatch 17/137, training loss 0.205368\n",
      "epoch 80, minibatch 57/137, training loss 0.222064\n",
      "epoch 80, minibatch 97/137, training loss 0.205869\n",
      "epoch 80, minibatch 137/137, validation loss 0.209514\n",
      "epoch 81, minibatch 0/137, training loss 0.204093\n",
      "epoch 81, minibatch 40/137, training loss 0.203713\n",
      "epoch 81, minibatch 80/137, training loss 0.210135\n",
      "epoch 81, minibatch 120/137, training loss 0.216609\n",
      "epoch 81, minibatch 137/137, validation loss 0.209305\n",
      "epoch 82, minibatch 23/137, training loss 0.214097\n",
      "epoch 82, minibatch 63/137, training loss 0.210618\n",
      "epoch 82, minibatch 103/137, training loss 0.222258\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# TRAIN MODEL #\n",
    "###############\n",
    "'''\n",
    "Define :\n",
    "    xx_loss : Cost function value\n",
    "    xx_score : Classification accuracy rate\n",
    "'''        \n",
    "    \n",
    "print('... training')\n",
    "    \n",
    "# early-stopping parameters\n",
    "patience = 10000  # look as this many examples regardless\n",
    "patience_increase = 2  # wait this much longer when a new best is\n",
    "                           # found\n",
    "improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                # considered significant\n",
    "validation_frequency = min(n_train_batches, patience // 2)\n",
    "                                  # go through this many\n",
    "                                  # minibatche before checking the network\n",
    "                                  # on the validation set; in this case we\n",
    "                                  # check every epoch\n",
    "    \n",
    "#validation_frequency = n_train_batches\n",
    "    \n",
    "best_iter = 0\n",
    "best_train_loss = np.inf\n",
    "best_validation_loss = np.inf  \n",
    "test_loss = np.inf\n",
    "train_score = 0.\n",
    "validation_score = 0.\n",
    "test_score = 0.    \n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "epoch = 0\n",
    "done_looping = False\n",
    "\n",
    "\n",
    "while (epoch < n_epochs) and (not done_looping):\n",
    "    epoch = epoch + 1\n",
    "        \n",
    "    for minibatch_index in range(n_train_batches):\n",
    "\n",
    "        [minibatch_avg_cost, pred, lab] = train_model(minibatch_index)\n",
    "        \n",
    "        # iteration number\n",
    "        iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "        \n",
    "        if iter%40 == 0:\n",
    "            print(\n",
    "                'epoch %i, minibatch %i/%i, training loss %f' %\n",
    "                (\n",
    "                    epoch,\n",
    "                    minibatch_index,\n",
    "                    n_train_batches,\n",
    "                    minibatch_avg_cost\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        #train_acc.append(get_acc(pred,np.nonzero(lab)[1]))\n",
    "        if (iter + 1) % validation_frequency == 0:\n",
    "            # compute loss on validation set\n",
    "            validation_losses = [validate_model(i) for i in range(n_valid_batches)] \n",
    "            this_validation_loss = np.mean(validation_losses)\n",
    "                \n",
    "            print(\n",
    "                'epoch %i, minibatch %i/%i, validation loss %f' %\n",
    "                (\n",
    "                    epoch,\n",
    "                    minibatch_index + 1,\n",
    "                    n_train_batches,\n",
    "                    this_validation_loss\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # if we got the best validation score until now\n",
    "            if this_validation_loss < best_validation_loss:\n",
    "                #improve patience if loss improvement is good enough\n",
    "                if (\n",
    "                    this_validation_loss < best_validation_loss *\n",
    "                    improvement_threshold\n",
    "                ):\n",
    "                    patience = max(patience, iter * patience_increase)\n",
    "                \n",
    "                #[test_pred, test_lab] = [test_model(i) for i in range(n_test_batches)] \n",
    "                #this_test_loss = np.mean(test_losses)\n",
    "                #test_acc.append(get_acc(test_pred,np.nonzero(lab)[1]))\n",
    "                    \n",
    "                    \n",
    "                best_validation_loss = this_validation_loss   \n",
    "                best_iter = iter\n",
    "          \n",
    "        \n",
    "                \n",
    "        if patience <= iter:\n",
    "            done_looping = True\n",
    "            break\n",
    "    '''\n",
    "    # compute loss on validation set\n",
    "        validation_losses = [validate_model(i) for i in range(n_valid_batches)] \n",
    "        this_validation_loss = np.mean(validation_losses)\n",
    "        print('epoch %i, minibatch %i/%i, validation loss %f ' %\n",
    "            (\n",
    "                epoch,\n",
    "                minibatch_index + 1,\n",
    "                n_train_batches,\n",
    "                this_validation_loss\n",
    "            )\n",
    "        )\n",
    "    '''        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred=test_model(0)\n",
    "[minibatch_avg_cost, pred, lab]=train_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa = test_pred[9]*255//1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa[aaa<10] = 0\n",
    "aaa=aaa.reshape(28,28)\n",
    "#print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbb=np.array(test[0][9])\n",
    "bbb=bbb.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEsxsa+3qSJKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a317dcc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBFqEIHwg0CL8fwYo6M5okj0PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a3171a610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(aaa)\n",
    "plt.figure(1)\n",
    "plt.imshow(aaa*255, cmap='gray')\n",
    "plt.show()\n",
    "plt.figure(2)\n",
    "plt.imshow(bbb*255, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
